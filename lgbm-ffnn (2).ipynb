{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36de4083",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-13T13:54:44.705808Z",
     "iopub.status.busy": "2023-12-13T13:54:44.700632Z",
     "iopub.status.idle": "2023-12-13T13:54:45.747951Z",
     "shell.execute_reply": "2023-12-13T13:54:45.747198Z",
     "shell.execute_reply.started": "2023-12-13T07:26:27.842964Z"
    },
    "papermill": {
     "duration": 1.089362,
     "end_time": "2023-12-13T13:54:45.748142",
     "exception": false,
     "start_time": "2023-12-13T13:54:44.658780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import glob\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from sklearn import preprocessing, model_selection\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler,LabelEncoder\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import numpy.matlib\n",
    "\n",
    "\n",
    "path_submissions = '/'\n",
    "\n",
    "target_name = 'target'\n",
    "scores_folds = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90067738",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T13:54:45.820923Z",
     "iopub.status.busy": "2023-12-13T13:54:45.820191Z",
     "iopub.status.idle": "2023-12-13T13:55:15.466600Z",
     "shell.execute_reply": "2023-12-13T13:55:15.465854Z",
     "shell.execute_reply.started": "2023-12-13T07:26:28.944320Z"
    },
    "papermill": {
     "duration": 29.684533,
     "end_time": "2023-12-13T13:55:15.466808",
     "exception": false,
     "start_time": "2023-12-13T13:54:45.782275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.10\r\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python --version\n",
    "!pip -q install ../input/tabnet/pytorch_tabnet-2.0.1-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe40c46",
   "metadata": {
    "papermill": {
     "duration": 0.034446,
     "end_time": "2023-12-13T13:55:15.536326",
     "exception": false,
     "start_time": "2023-12-13T13:55:15.501880",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* ### I just tried different parameters and weights of 2  models. Cross validation with different folds was also attempted, but failed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f371e3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T13:55:15.659224Z",
     "iopub.status.busy": "2023-12-13T13:55:15.620632Z",
     "iopub.status.idle": "2023-12-13T13:55:15.679690Z",
     "shell.execute_reply": "2023-12-13T13:55:15.679236Z",
     "shell.execute_reply.started": "2023-12-13T07:26:58.390345Z"
    },
    "papermill": {
     "duration": 0.111264,
     "end_time": "2023-12-13T13:55:15.679846",
     "exception": false,
     "start_time": "2023-12-13T13:55:15.568582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data directory\n",
    "data_dir = '../input/optiver-realized-volatility-prediction/'\n",
    "\n",
    "# Function to calculate first WAP\n",
    "def calc_wap1(df):\n",
    "    wap = (df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * df['bid_size1']) / (df['bid_size1'] + df['ask_size1'])\n",
    "    return wap\n",
    "\n",
    "# Function to calculate second WAP\n",
    "def calc_wap2(df):\n",
    "    wap = (df['bid_price2'] * df['ask_size2'] + df['ask_price2'] * df['bid_size2']) / (df['bid_size2'] + df['ask_size2'])\n",
    "    return wap\n",
    "\n",
    "def calc_wap3(df):\n",
    "    wap = (df['bid_price1'] * df['bid_size1'] + df['ask_price1'] * df['ask_size1']) / (df['bid_size1'] + df['ask_size1'])\n",
    "    return wap\n",
    "\n",
    "def calc_wap4(df):\n",
    "    wap = (df['bid_price2'] * df['bid_size2'] + df['ask_price2'] * df['ask_size2']) / (df['bid_size2'] + df['ask_size2'])\n",
    "    return wap\n",
    "\n",
    "# Function to calculate the log of the return\n",
    "# Remember that logb(x / y) = logb(x) - logb(y)\n",
    "def log_return(series):\n",
    "    return np.log(series).diff()\n",
    "\n",
    "# Calculate the realized volatility\n",
    "def realized_volatility(series):\n",
    "    return np.sqrt(np.sum(series**2))\n",
    "\n",
    "#我加的===================================================================\n",
    "\n",
    "def RSI(close,n):\n",
    "    delta = close.diff()\n",
    "    delta = delta[1:]\n",
    "    pricesUp = delta.copy()\n",
    "    pricesDown = delta.copy()\n",
    "    pricesUp[pricesUp < 0] = 0\n",
    "    pricesDown[pricesDown > 0] = 0\n",
    "    rollUp = pricesUp.rolling(n).mean()\n",
    "    rollDown = pricesDown.abs().rolling(n).mean()\n",
    "    rs = rollUp / rollDown\n",
    "    rsi = 100.0 - (100.0 / (1.0 + rs))\n",
    "    return rsi\n",
    "\n",
    "#========================================================================\n",
    "\n",
    "# Function to count unique elements of a series\n",
    "def count_unique(series):\n",
    "    return len(np.unique(series))\n",
    "\n",
    "# Function to read our base train and test set\n",
    "def read_train_test():\n",
    "    train = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\n",
    "    test = pd.read_csv('../input/optiver-realized-volatility-prediction/test.csv')\n",
    "#     train = train[:100]\n",
    "#     test=test[:100]\n",
    "    # Create a key to merge with book and trade data\n",
    "    train['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\n",
    "    test['row_id'] = test['stock_id'].astype(str) + '-' + test['time_id'].astype(str)\n",
    "    \n",
    "    print(f'Our training set has {train.shape[0]} rows')\n",
    "    return train, test\n",
    "\n",
    "# Function to preprocess book data (for each stock id)\n",
    "def book_preprocessor(file_path):\n",
    "    df = pd.read_parquet(file_path)\n",
    "    # Calculate Wap\n",
    "    df['wap1'] = calc_wap1(df)\n",
    "    df['wap2'] = calc_wap2(df)\n",
    "    df['wap3'] = calc_wap3(df)\n",
    "    df['wap4'] = calc_wap4(df)\n",
    "    # Calculate log returns\n",
    "    df['log_return1'] = df.groupby(['time_id'])['wap1'].apply(log_return)\n",
    "    df['log_return2'] = df.groupby(['time_id'])['wap2'].apply(log_return)\n",
    "    df['log_return3'] = df.groupby(['time_id'])['wap3'].apply(log_return)\n",
    "    df['log_return4'] = df.groupby(['time_id'])['wap4'].apply(log_return)\n",
    "    # Calculate wap balance\n",
    "    df['wap_balance'] = abs(df['wap1'] - df['wap2'])\n",
    "    # Calculate spread\n",
    "    df['price_spread'] = (df['ask_price1'] - df['bid_price1']) / ((df['ask_price1'] + df['bid_price1']) / 2)\n",
    "    df['price_spread2'] = (df['ask_price2'] - df['bid_price2']) / ((df['ask_price2'] + df['bid_price2']) / 2)\n",
    "    df['bid_spread'] = df['bid_price1'] - df['bid_price2']\n",
    "    df['ask_spread'] = df['ask_price1'] - df['ask_price2']\n",
    "    df[\"bid_ask_spread\"] = abs(df['bid_spread'] - df['ask_spread'])\n",
    "    df['total_volume'] = (df['ask_size1'] + df['ask_size2']) + (df['bid_size1'] + df['bid_size2'])\n",
    "    df['volume_imbalance'] = abs((df['ask_size1'] + df['ask_size2']) - (df['bid_size1'] + df['bid_size2']))\n",
    "    \n",
    "    # Dict for aggregations\n",
    "    create_feature_dict = {\n",
    "        'wap1': [np.sum, np.mean, np.std],\n",
    "        'wap2': [np.sum, np.mean, np.std],\n",
    "        'wap3': [np.sum, np.mean, np.std],\n",
    "        'wap4': [np.sum, np.mean, np.std],\n",
    "        'log_return1': [np.sum, realized_volatility, np.mean, np.std],\n",
    "        'log_return2': [np.sum, realized_volatility, np.mean, np.std],\n",
    "        'log_return3': [np.sum, realized_volatility, np.mean, np.std],\n",
    "        'log_return4': [np.sum, realized_volatility, np.mean, np.std],\n",
    "        'wap_balance': [np.sum, np.mean, np.std],\n",
    "        'price_spread':[np.sum, np.mean, np.std],\n",
    "        'price_spread2':[np.sum, np.mean, np.std],\n",
    "        'bid_spread':[np.sum, np.mean, np.std],\n",
    "        'ask_spread':[np.sum, np.mean, np.std],\n",
    "        'total_volume':[np.sum, np.mean, np.std],\n",
    "        'volume_imbalance':[np.sum, np.mean, np.std],\n",
    "        \"bid_ask_spread\":[np.sum, np.mean, np.std],\n",
    "    }\n",
    "    create_feature_dict_time = {\n",
    "        'log_return1': [realized_volatility],\n",
    "        'log_return2': [realized_volatility],\n",
    "        'log_return3': [realized_volatility],\n",
    "        'log_return4': [realized_volatility],\n",
    "    }\n",
    "    \n",
    "    # Function to get group stats for different windows (seconds in bucket)\n",
    "    def get_stats_window(fe_dict,seconds_in_bucket, add_suffix = False):\n",
    "        # Group by the window\n",
    "        df_feature = df[df['seconds_in_bucket'] >= seconds_in_bucket].groupby(['time_id']).agg(fe_dict).reset_index()\n",
    "        # Rename columns joining suffix\n",
    "        df_feature.columns = ['_'.join(col) for col in df_feature.columns]\n",
    "        # Add a suffix to differentiate windows\n",
    "        if add_suffix:\n",
    "            df_feature = df_feature.add_suffix('_' + str(seconds_in_bucket))\n",
    "        return df_feature\n",
    "    \n",
    "    # Get the stats for different windows\n",
    "    df_feature = get_stats_window(create_feature_dict,seconds_in_bucket = 0, add_suffix = False)\n",
    "    df_feature_500 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 500, add_suffix = True)\n",
    "    df_feature_400 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 400, add_suffix = True)\n",
    "    df_feature_300 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 300, add_suffix = True)\n",
    "    df_feature_200 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 200, add_suffix = True)\n",
    "    df_feature_100 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 100, add_suffix = True)\n",
    "\n",
    "    # Merge all\n",
    "    df_feature = df_feature.merge(df_feature_500, how = 'left', left_on = 'time_id_', right_on = 'time_id__500')\n",
    "    df_feature = df_feature.merge(df_feature_400, how = 'left', left_on = 'time_id_', right_on = 'time_id__400')\n",
    "    df_feature = df_feature.merge(df_feature_300, how = 'left', left_on = 'time_id_', right_on = 'time_id__300')\n",
    "    df_feature = df_feature.merge(df_feature_200, how = 'left', left_on = 'time_id_', right_on = 'time_id__200')\n",
    "    df_feature = df_feature.merge(df_feature_100, how = 'left', left_on = 'time_id_', right_on = 'time_id__100')\n",
    "    # Drop unnecesary time_ids\n",
    "    df_feature.drop(['time_id__500','time_id__400', 'time_id__300', 'time_id__200','time_id__100'], axis = 1, inplace = True)\n",
    "    \n",
    "    #我加的===================================================================\n",
    "    df_new_features = df[['time_id']].copy()\n",
    "    df['mid'] = (df['ask_price1']+ df['bid_price1'])/2\n",
    "    #STD(price)\n",
    "    for window in [100,200,300,400,500]:\n",
    "        df[f'mid_ma_{window}'] = df['mid'].rolling(window=window).mean()\n",
    "        #|price-MA|\n",
    "        df[f'price_to_ma_{window}'] = abs(df['mid'] - df[f'mid_ma_{window}'])\n",
    "        df[f'price_to_ma_{window}'].bfill(inplace=True)\n",
    "        df_new_features[f'price_to_ma_{window}'] = df.groupby('time_id')[f'price_to_ma_{window}'].transform('mean')\n",
    "    for n in [30,60,100]:\n",
    "        df[f'rsi_{n}']=RSI(df['mid'],n=n)\n",
    "        df[f'rsi_{n}'].bfill(inplace=True)\n",
    "        df_new_features[f'rsi_{n}'] = df.groupby('time_id')[f'rsi_{n}'].transform('mean')\n",
    "    df_new_features.drop_duplicates(subset='time_id', keep='first', inplace=True)     \n",
    "    df_feature = df_feature.merge(df_new_features, how = 'left', left_on = 'time_id_', right_on = 'time_id')\n",
    "    df_feature.drop(['time_id'], axis = 1, inplace = True)\n",
    "    #我加的===================================================================\n",
    "    \n",
    "    # Create row_id so we can merge\n",
    "    stock_id = file_path.split('=')[1]\n",
    "    df_feature['row_id'] = df_feature['time_id_'].apply(lambda x: f'{stock_id}-{x}')\n",
    "    df_feature.drop(['time_id_'], axis = 1, inplace = True)\n",
    "    return df_feature\n",
    "\n",
    "# Function to preprocess trade data (for each stock id)\n",
    "def trade_preprocessor(file_path):\n",
    "    df = pd.read_parquet(file_path)\n",
    "    df['log_return'] = df.groupby('time_id')['price'].apply(log_return)\n",
    "    df['amount']=df['price']*df['size']\n",
    "    # Dict for aggregations\n",
    "    create_feature_dict = {\n",
    "        'log_return':[realized_volatility],\n",
    "        'seconds_in_bucket':[count_unique],\n",
    "        'size':[np.sum, np.max, np.min],\n",
    "        'order_count':[np.sum,np.max],\n",
    "        'amount':[np.sum,np.max,np.min],\n",
    "    }\n",
    "    create_feature_dict_time = {\n",
    "        'log_return':[realized_volatility],\n",
    "        'seconds_in_bucket':[count_unique],\n",
    "        'size':[np.sum],\n",
    "        'order_count':[np.sum],\n",
    "    }\n",
    "    # Function to get group stats for different windows (seconds in bucket)\n",
    "    def get_stats_window(fe_dict,seconds_in_bucket, add_suffix = False):\n",
    "        # Group by the window\n",
    "        df_feature = df[df['seconds_in_bucket'] >= seconds_in_bucket].groupby(['time_id']).agg(fe_dict).reset_index()\n",
    "        # Rename columns joining suffix\n",
    "        df_feature.columns = ['_'.join(col) for col in df_feature.columns]\n",
    "        # Add a suffix to differentiate windows\n",
    "        if add_suffix:\n",
    "            df_feature = df_feature.add_suffix('_' + str(seconds_in_bucket))\n",
    "        return df_feature\n",
    "    \n",
    "\n",
    "    # Get the stats for different windows\n",
    "    df_feature = get_stats_window(create_feature_dict,seconds_in_bucket = 0, add_suffix = False)\n",
    "    df_feature_500 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 500, add_suffix = True)\n",
    "    df_feature_400 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 400, add_suffix = True)\n",
    "    df_feature_300 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 300, add_suffix = True)\n",
    "    df_feature_200 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 200, add_suffix = True)\n",
    "    df_feature_100 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 100, add_suffix = True)\n",
    "    \n",
    "    def tendency(price, vol):    \n",
    "        df_diff = np.diff(price)\n",
    "        val = (df_diff/price[1:])*100\n",
    "        power = np.sum(val*vol[1:])\n",
    "        return(power)\n",
    "    \n",
    "    lis = []\n",
    "    for n_time_id in df['time_id'].unique():\n",
    "        df_id = df[df['time_id'] == n_time_id]        \n",
    "        tendencyV = tendency(df_id['price'].values, df_id['size'].values)      \n",
    "        f_max = np.sum(df_id['price'].values > np.mean(df_id['price'].values))\n",
    "        f_min = np.sum(df_id['price'].values < np.mean(df_id['price'].values))\n",
    "        df_max =  np.sum(np.diff(df_id['price'].values) > 0)\n",
    "        df_min =  np.sum(np.diff(df_id['price'].values) < 0)\n",
    "        # new\n",
    "        abs_diff = np.median(np.abs( df_id['price'].values - np.mean(df_id['price'].values)))        \n",
    "        energy = np.mean(df_id['price'].values**2)\n",
    "        iqr_p = np.percentile(df_id['price'].values,75) - np.percentile(df_id['price'].values,25)\n",
    "        \n",
    "        # vol vars\n",
    "        \n",
    "        abs_diff_v = np.median(np.abs( df_id['size'].values - np.mean(df_id['size'].values)))        \n",
    "        energy_v = np.sum(df_id['size'].values**2)\n",
    "        iqr_p_v = np.percentile(df_id['size'].values,75) - np.percentile(df_id['size'].values,25)\n",
    "        \n",
    "        lis.append({'time_id':n_time_id,'tendency':tendencyV,'f_max':f_max,'f_min':f_min,'df_max':df_max,'df_min':df_min,\n",
    "                   'abs_diff':abs_diff,'energy':energy,'iqr_p':iqr_p,'abs_diff_v':abs_diff_v,'energy_v':energy_v,'iqr_p_v':iqr_p_v})\n",
    "    \n",
    "    df_lr = pd.DataFrame(lis)\n",
    "        \n",
    "   \n",
    "    df_feature = df_feature.merge(df_lr, how = 'left', left_on = 'time_id_', right_on = 'time_id')\n",
    "    \n",
    "    # Merge all\n",
    "    df_feature = df_feature.merge(df_feature_500, how = 'left', left_on = 'time_id_', right_on = 'time_id__500')\n",
    "    df_feature = df_feature.merge(df_feature_400, how = 'left', left_on = 'time_id_', right_on = 'time_id__400')\n",
    "    df_feature = df_feature.merge(df_feature_300, how = 'left', left_on = 'time_id_', right_on = 'time_id__300')\n",
    "    df_feature = df_feature.merge(df_feature_200, how = 'left', left_on = 'time_id_', right_on = 'time_id__200')\n",
    "    df_feature = df_feature.merge(df_feature_100, how = 'left', left_on = 'time_id_', right_on = 'time_id__100')\n",
    "    # Drop unnecesary time_ids\n",
    "    df_feature.drop(['time_id__500','time_id__400', 'time_id__300', 'time_id__200','time_id','time_id__100'], axis = 1, inplace = True)\n",
    "    \n",
    "    \n",
    "    df_feature = df_feature.add_prefix('trade_')\n",
    "    stock_id = file_path.split('=')[1]\n",
    "    df_feature['row_id'] = df_feature['trade_time_id_'].apply(lambda x:f'{stock_id}-{x}')\n",
    "    df_feature.drop(['trade_time_id_'], axis = 1, inplace = True)\n",
    "    return df_feature\n",
    "\n",
    "# Function to get group stats for the stock_id and time_id\n",
    "def get_time_stock(df):\n",
    "    vol_cols = ['log_return1_realized_volatility', 'log_return2_realized_volatility', 'log_return1_realized_volatility_400', 'log_return2_realized_volatility_400', \n",
    "                'log_return1_realized_volatility_300', 'log_return2_realized_volatility_300', 'log_return1_realized_volatility_200', 'log_return2_realized_volatility_200', \n",
    "                'trade_log_return_realized_volatility', 'trade_log_return_realized_volatility_400', 'trade_log_return_realized_volatility_300', 'trade_log_return_realized_volatility_200']\n",
    "\n",
    "\n",
    "    # Group by the stock id\n",
    "    df_stock_id = df.groupby(['stock_id'])[vol_cols].agg(['mean', 'std', 'max', 'min', ]).reset_index()\n",
    "    # Rename columns joining suffix\n",
    "    df_stock_id.columns = ['_'.join(col) for col in df_stock_id.columns]\n",
    "    df_stock_id = df_stock_id.add_suffix('_' + 'stock')\n",
    "\n",
    "    # Group by the stock id\n",
    "    df_time_id = df.groupby(['time_id'])[vol_cols].agg(['mean', 'std', 'max', 'min', ]).reset_index()\n",
    "    # Rename columns joining suffix\n",
    "    df_time_id.columns = ['_'.join(col) for col in df_time_id.columns]\n",
    "    df_time_id = df_time_id.add_suffix('_' + 'time')\n",
    "    \n",
    "    # Merge with original dataframe\n",
    "    df = df.merge(df_stock_id, how = 'left', left_on = ['stock_id'], right_on = ['stock_id__stock'])\n",
    "    df = df.merge(df_time_id, how = 'left', left_on = ['time_id'], right_on = ['time_id__time'])\n",
    "    df.drop(['stock_id__stock', 'time_id__time'], axis = 1, inplace = True)\n",
    "    return df\n",
    "    \n",
    "# Funtion to make preprocessing function in parallel (for each stock id)\n",
    "def preprocessor(list_stock_ids, is_train = True):\n",
    "    \n",
    "    # Parrallel for loop\n",
    "    def for_joblib(stock_id):\n",
    "        # Train\n",
    "        if is_train:\n",
    "            file_path_book = data_dir + \"book_train.parquet/stock_id=\" + str(stock_id)\n",
    "            file_path_trade = data_dir + \"trade_train.parquet/stock_id=\" + str(stock_id)\n",
    "        # Test\n",
    "        else:\n",
    "            file_path_book = data_dir + \"book_test.parquet/stock_id=\" + str(stock_id)\n",
    "            file_path_trade = data_dir + \"trade_test.parquet/stock_id=\" + str(stock_id)\n",
    "    \n",
    "        # Preprocess book and trade data and merge them\n",
    "        df_tmp = pd.merge(book_preprocessor(file_path_book), trade_preprocessor(file_path_trade), on = 'row_id', how = 'left')\n",
    "        \n",
    "        # Return the merge dataframe\n",
    "        return df_tmp\n",
    "    \n",
    "    # Use parallel api to call paralle for loop\n",
    "    df = Parallel(n_jobs = -1, verbose = 1)(delayed(for_joblib)(stock_id) for stock_id in list_stock_ids)\n",
    "    # Concatenate all the dataframes that return from Parallel\n",
    "    df = pd.concat(df, ignore_index = True)\n",
    "    return df\n",
    "\n",
    "# Function to calculate the root mean squared percentage error\n",
    "def rmspe(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "\n",
    "# Function to early stop with root mean squared percentage error\n",
    "def feval_rmspe(y_pred, lgb_train):\n",
    "    y_true = lgb_train.get_label()\n",
    "    return 'RMSPE', rmspe(y_true, y_pred), False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5442006",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T13:55:15.751756Z",
     "iopub.status.busy": "2023-12-13T13:55:15.751130Z",
     "iopub.status.idle": "2023-12-13T14:37:46.894683Z",
     "shell.execute_reply": "2023-12-13T14:37:46.893935Z",
     "shell.execute_reply.started": "2023-12-13T07:26:58.468896Z"
    },
    "papermill": {
     "duration": 2551.182912,
     "end_time": "2023-12-13T14:37:46.894879",
     "exception": false,
     "start_time": "2023-12-13T13:55:15.711967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our training set has 428932 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 16.5min\n",
      "[Parallel(n_jobs=-1)]: Done 112 out of 112 | elapsed: 42.3min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "# Read train and test\n",
    "train, test = read_train_test()\n",
    "\n",
    "# Get unique stock ids \n",
    "train_stock_ids = train['stock_id'].unique()\n",
    "# Preprocess them using Parallel and our single stock id functions\n",
    "train_ = preprocessor(train_stock_ids, is_train = True)\n",
    "train = train.merge(train_, on = ['row_id'], how = 'left')\n",
    "\n",
    "# Get unique stock ids \n",
    "test_stock_ids = test['stock_id'].unique()\n",
    "# Preprocess them using Parallel and our single stock id functions\n",
    "test_ = preprocessor(test_stock_ids, is_train = False)\n",
    "test = test.merge(test_, on = ['row_id'], how = 'left')\n",
    "\n",
    "# Get group stats of time_id and stock_id\n",
    "train = get_time_stock(train)\n",
    "test = get_time_stock(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1185bd73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T14:37:46.979939Z",
     "iopub.status.busy": "2023-12-13T14:37:46.978662Z",
     "iopub.status.idle": "2023-12-13T14:37:46.996134Z",
     "shell.execute_reply": "2023-12-13T14:37:46.995483Z",
     "shell.execute_reply.started": "2023-12-13T08:07:48.856054Z"
    },
    "papermill": {
     "duration": 0.063217,
     "end_time": "2023-12-13T14:37:46.996261",
     "exception": false,
     "start_time": "2023-12-13T14:37:46.933044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# replace by order sum (tau)\n",
    "train['size_tau'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique'] )\n",
    "test['size_tau'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique'] )\n",
    "#train['size_tau_450'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_450'] )\n",
    "#test['size_tau_450'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_450'] )\n",
    "train['size_tau_400'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_400'] )\n",
    "test['size_tau_400'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_400'] )\n",
    "train['size_tau_300'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_300'] )\n",
    "test['size_tau_300'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_300'] )\n",
    "#train['size_tau_150'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_150'] )\n",
    "#test['size_tau_150'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_150'] )\n",
    "train['size_tau_200'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_200'] )\n",
    "test['size_tau_200'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_200'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7bb689f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T14:37:47.072759Z",
     "iopub.status.busy": "2023-12-13T14:37:47.072149Z",
     "iopub.status.idle": "2023-12-13T14:37:47.090871Z",
     "shell.execute_reply": "2023-12-13T14:37:47.090321Z",
     "shell.execute_reply.started": "2023-12-13T08:07:48.879919Z"
    },
    "papermill": {
     "duration": 0.060214,
     "end_time": "2023-12-13T14:37:47.091003",
     "exception": false,
     "start_time": "2023-12-13T14:37:47.030789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train['size_tau2'] = np.sqrt( 1/ train['trade_order_count_sum'] )\n",
    "test['size_tau2'] = np.sqrt( 1/ test['trade_order_count_sum'] )\n",
    "#train['size_tau2_450'] = np.sqrt( 0.25/ train['trade_order_count_sum'] )\n",
    "#test['size_tau2_450'] = np.sqrt( 0.25/ test['trade_order_count_sum'] )\n",
    "train['size_tau2_400'] = np.sqrt( 0.33/ train['trade_order_count_sum'] )\n",
    "test['size_tau2_400'] = np.sqrt( 0.33/ test['trade_order_count_sum'] )\n",
    "train['size_tau2_300'] = np.sqrt( 0.5/ train['trade_order_count_sum'] )\n",
    "test['size_tau2_300'] = np.sqrt( 0.5/ test['trade_order_count_sum'] )\n",
    "#train['size_tau2_150'] = np.sqrt( 0.75/ train['trade_order_count_sum'] )\n",
    "#test['size_tau2_150'] = np.sqrt( 0.75/ test['trade_order_count_sum'] )\n",
    "train['size_tau2_200'] = np.sqrt( 0.66/ train['trade_order_count_sum'] )\n",
    "test['size_tau2_200'] = np.sqrt( 0.66/ test['trade_order_count_sum'] )\n",
    "\n",
    "# delta tau\n",
    "train['size_tau2_d'] = train['size_tau2_400'] - train['size_tau2']\n",
    "test['size_tau2_d'] = test['size_tau2_400'] - test['size_tau2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fc4681a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T14:37:47.170673Z",
     "iopub.status.busy": "2023-12-13T14:37:47.169873Z",
     "iopub.status.idle": "2023-12-13T14:37:47.173207Z",
     "shell.execute_reply": "2023-12-13T14:37:47.173778Z",
     "shell.execute_reply.started": "2023-12-13T08:07:48.904976Z"
    },
    "papermill": {
     "duration": 0.047174,
     "end_time": "2023-12-13T14:37:47.173939",
     "exception": false,
     "start_time": "2023-12-13T14:37:47.126765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colNames = [col for col in list(train.columns)\n",
    "            if col not in {\"stock_id\", \"time_id\", \"target\", \"row_id\"}]\n",
    "len(colNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbbf114a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T14:37:47.255496Z",
     "iopub.status.busy": "2023-12-13T14:37:47.254911Z",
     "iopub.status.idle": "2023-12-13T14:37:49.708468Z",
     "shell.execute_reply": "2023-12-13T14:37:49.707800Z",
     "shell.execute_reply.started": "2023-12-13T08:07:48.916652Z"
    },
    "papermill": {
     "duration": 2.498786,
     "end_time": "2023-12-13T14:37:49.708624",
     "exception": false,
     "start_time": "2023-12-13T14:37:47.209838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 4 2 1 1 2 4 6 2 1 0 4 4 1 1 1 2 4 4 4 0 1 1 3 1 1 4 3 4 3 4 4 1 3 3 4\n",
      " 3 4 1 4 1 4 4 1 0 4 4 1 0 0 3 3 3 2 0 2 4 1 4 4 1 4 1 0 3 3 0 3 0 6 5 3 3\n",
      " 0 1 2 0 3 3 3 4 1 1 0 2 3 3 1 0 1 4 4 4 4 4 1 3 1 0 1 4 1 0 1 4 1 0 4 0 4\n",
      " 0]\n",
      "[1, 11, 22, 50, 55, 56, 62, 73, 76, 78, 84, 87, 96, 101, 112, 116, 122, 124, 126]\n",
      "(0, 227)\n",
      "[0, 4, 5, 10, 15, 16, 17, 23, 26, 28, 29, 36, 42, 44, 48, 53, 66, 69, 72, 85, 94, 95, 100, 102, 109, 111, 113, 115, 118, 120]\n",
      "(3, 227)\n",
      "[3, 6, 9, 18, 61, 63, 86, 97]\n",
      "(0, 227)\n",
      "[27, 31, 33, 37, 38, 40, 58, 59, 60, 74, 75, 77, 82, 83, 88, 89, 90, 98, 99, 110]\n",
      "(0, 227)\n",
      "[2, 7, 13, 14, 19, 20, 21, 30, 32, 34, 35, 39, 41, 43, 46, 47, 51, 52, 64, 67, 68, 70, 93, 103, 104, 105, 107, 108, 114, 119, 123, 125]\n",
      "(0, 227)\n",
      "[81]\n",
      "(0, 227)\n",
      "[8, 80]\n",
      "(0, 227)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# making agg features\n",
    "\n",
    "train_p = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\n",
    "train_p = train_p.pivot(index='time_id', columns='stock_id', values='target')\n",
    "\n",
    "corr = train_p.corr()\n",
    "\n",
    "ids = corr.index\n",
    "\n",
    "kmeans = KMeans(n_clusters=7, random_state=0).fit(corr.values)\n",
    "print(kmeans.labels_)\n",
    "\n",
    "l = []\n",
    "for n in range(7):\n",
    "    l.append ( [ (x-1) for x in ( (ids+1)*(kmeans.labels_ == n)) if x > 0] )\n",
    "    \n",
    "\n",
    "mat = []\n",
    "matTest = []\n",
    "\n",
    "n = 0\n",
    "for ind in l:\n",
    "    print(ind)\n",
    "    newDf = train.loc[train['stock_id'].isin(ind) ]\n",
    "    newDf = newDf.groupby(['time_id']).agg(np.nanmean)\n",
    "    newDf.loc[:,'stock_id'] = str(n)+'c1'\n",
    "    mat.append ( newDf )\n",
    "    \n",
    "    newDf = test.loc[test['stock_id'].isin(ind) ]    \n",
    "    newDf = newDf.groupby(['time_id']).agg(np.nanmean)\n",
    "    newDf.loc[:,'stock_id'] = str(n)+'c1'\n",
    "    matTest.append ( newDf )\n",
    "    print(newDf.shape)\n",
    "    n+=1\n",
    "    \n",
    "mat1 = pd.concat(mat).reset_index()\n",
    "mat1.drop(columns=['target'],inplace=True)\n",
    "\n",
    "mat2 = pd.concat(matTest).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "027402f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T14:37:49.793737Z",
     "iopub.status.busy": "2023-12-13T14:37:49.793087Z",
     "iopub.status.idle": "2023-12-13T14:37:49.993814Z",
     "shell.execute_reply": "2023-12-13T14:37:49.994302Z",
     "shell.execute_reply.started": "2023-12-13T08:07:51.323093Z"
    },
    "papermill": {
     "duration": 0.247066,
     "end_time": "2023-12-13T14:37:49.994464",
     "exception": false,
     "start_time": "2023-12-13T14:37:49.747398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: Index.ravel returning ndarray is deprecated; in a future version this will return a view on self.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: FutureWarning: Index.ravel returning ndarray is deprecated; in a future version this will return a view on self.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "mat2 = pd.concat([mat2,mat1.loc[mat1.time_id==5]])\n",
    "mat1 = mat1.pivot(index='time_id', columns='stock_id')\n",
    "mat1.columns = [\"_\".join(x) for x in mat1.columns.ravel()]\n",
    "mat1.reset_index(inplace=True)\n",
    "\n",
    "mat2 = mat2.pivot(index='time_id', columns='stock_id')\n",
    "mat2.columns = [\"_\".join(x) for x in mat2.columns.ravel()]\n",
    "mat2.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd2dbfb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T14:37:50.081689Z",
     "iopub.status.busy": "2023-12-13T14:37:50.080764Z",
     "iopub.status.idle": "2023-12-13T14:38:08.693033Z",
     "shell.execute_reply": "2023-12-13T14:38:08.692355Z",
     "shell.execute_reply.started": "2023-12-13T08:07:51.520585Z"
    },
    "papermill": {
     "duration": 18.659606,
     "end_time": "2023-12-13T14:38:08.693177",
     "exception": false,
     "start_time": "2023-12-13T14:37:50.033571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      time_id  wap1_sum_0c1  wap1_sum_1c1  wap1_sum_2c1  wap1_sum_3c1  \\\n",
      "0           5    454.259460    450.296722    410.733185    350.107635   \n",
      "1          11    338.439728    320.296692    278.055267    233.907928   \n",
      "2          16    352.636505    360.082367    347.626770    256.215057   \n",
      "3          31    312.892395    302.954620    298.578033    231.109253   \n",
      "4          62    327.286407    314.466064    315.001099    210.724350   \n",
      "...       ...           ...           ...           ...           ...   \n",
      "3825    32751    419.968994    395.118561    361.749359    297.389282   \n",
      "3826    32753    372.915985    347.497681    303.217072    275.159363   \n",
      "3827    32758    311.283264    327.945435    290.676208    234.331451   \n",
      "3828    32763    443.204437    451.020905    408.540771    354.972992   \n",
      "3829    32767    357.900848    373.544617    305.278687    252.666580   \n",
      "\n",
      "      wap1_sum_4c1  wap1_sum_5c1  wap1_sum_6c1  wap1_mean_0c1  wap1_mean_1c1  \\\n",
      "0       506.105530    537.815308    476.310425       1.003184       1.002290   \n",
      "1       358.379181    281.177979    423.141602       1.000956       1.000588   \n",
      "2       420.425507    355.364594    284.772736       1.000108       0.999730   \n",
      "3       343.913910    449.594482    366.892456       0.999307       0.999252   \n",
      "4       355.398346    218.791824    407.402344       0.999301       0.999558   \n",
      "...            ...           ...           ...            ...            ...   \n",
      "3825    467.723602    338.286774    451.196350       0.999238       0.999701   \n",
      "3826    410.243500    281.197662    362.701538       1.000772       0.999747   \n",
      "3827    381.826019    268.066437    214.089966       1.001127       1.000425   \n",
      "3828    494.760376    467.120056    392.955444       1.001051       1.001303   \n",
      "3829    419.389618    313.938019    423.653992       0.999563       1.000014   \n",
      "\n",
      "      ...  size_tau2_200_4c1  size_tau2_200_5c1  size_tau2_200_6c1  \\\n",
      "0     ...           0.044431           0.044926           0.041189   \n",
      "1     ...           0.063868           0.051484           0.037159   \n",
      "2     ...           0.060912           0.036405           0.065579   \n",
      "3     ...           0.076921           0.037837           0.045045   \n",
      "4     ...           0.070177           0.076425           0.037661   \n",
      "...   ...                ...                ...                ...   \n",
      "3825  ...           0.050041           0.047871           0.033436   \n",
      "3826  ...           0.050737           0.048901           0.050758   \n",
      "3827  ...           0.073582           0.060722           0.097900   \n",
      "3828  ...           0.041723           0.047706           0.033103   \n",
      "3829  ...           0.064281           0.064226           0.043765   \n",
      "\n",
      "      size_tau2_d_0c1  size_tau2_d_1c1  size_tau2_d_2c1  size_tau2_d_3c1  \\\n",
      "0           -0.024915        -0.024369        -0.027101        -0.033393   \n",
      "1           -0.034569        -0.033599        -0.037332        -0.052039   \n",
      "2           -0.033426        -0.037183        -0.027899        -0.049481   \n",
      "3           -0.042717        -0.038160        -0.032851        -0.045086   \n",
      "4           -0.037143        -0.037902        -0.035379        -0.047943   \n",
      "...               ...              ...              ...              ...   \n",
      "3825        -0.027396        -0.027238        -0.027789        -0.038157   \n",
      "3826        -0.031339        -0.028047        -0.035711        -0.036298   \n",
      "3827        -0.041982        -0.039200        -0.041714        -0.052872   \n",
      "3828        -0.021978        -0.023091        -0.023470        -0.028788   \n",
      "3829        -0.032925        -0.033441        -0.036363        -0.046284   \n",
      "\n",
      "      size_tau2_d_4c1  size_tau2_d_5c1  size_tau2_d_6c1  \n",
      "0           -0.023273        -0.023533        -0.021575  \n",
      "1           -0.033454        -0.026968        -0.019464  \n",
      "2           -0.031906        -0.019069        -0.034351  \n",
      "3           -0.040292        -0.019820        -0.023595  \n",
      "4           -0.036759        -0.040032        -0.019727  \n",
      "...               ...              ...              ...  \n",
      "3825        -0.026212        -0.025075        -0.017514  \n",
      "3826        -0.026576        -0.025615        -0.026587  \n",
      "3827        -0.038543        -0.031807        -0.051281  \n",
      "3828        -0.021855        -0.024989        -0.017340  \n",
      "3829        -0.033671        -0.033642        -0.022924  \n",
      "\n",
      "[3830 rows x 1583 columns]\n"
     ]
    }
   ],
   "source": [
    "nnn = ['time_id',\n",
    "     'log_return1_realized_volatility_0c1',\n",
    "     'log_return1_realized_volatility_1c1',     \n",
    "     'log_return1_realized_volatility_3c1',\n",
    "     'log_return1_realized_volatility_4c1',     \n",
    "     'log_return1_realized_volatility_6c1',\n",
    "     'total_volume_sum_0c1',\n",
    "     'total_volume_sum_1c1', \n",
    "     'total_volume_sum_3c1',\n",
    "     'total_volume_sum_4c1', \n",
    "     'total_volume_sum_6c1',\n",
    "     'trade_size_sum_0c1',\n",
    "     'trade_size_sum_1c1', \n",
    "     'trade_size_sum_3c1',\n",
    "     'trade_size_sum_4c1', \n",
    "     'trade_size_sum_6c1',\n",
    "     'trade_order_count_sum_0c1',\n",
    "     'trade_order_count_sum_1c1',\n",
    "     'trade_order_count_sum_3c1',\n",
    "     'trade_order_count_sum_4c1',\n",
    "     'trade_order_count_sum_6c1',      \n",
    "     'price_spread_sum_0c1',\n",
    "     'price_spread_sum_1c1',\n",
    "     'price_spread_sum_3c1',\n",
    "     'price_spread_sum_4c1',\n",
    "     'price_spread_sum_6c1',   \n",
    "     'bid_spread_sum_0c1',\n",
    "     'bid_spread_sum_1c1',\n",
    "     'bid_spread_sum_3c1',\n",
    "     'bid_spread_sum_4c1',\n",
    "     'bid_spread_sum_6c1',       \n",
    "     'ask_spread_sum_0c1',\n",
    "     'ask_spread_sum_1c1',\n",
    "     'ask_spread_sum_3c1',\n",
    "     'ask_spread_sum_4c1',\n",
    "     'ask_spread_sum_6c1',   \n",
    "     'volume_imbalance_sum_0c1',\n",
    "     'volume_imbalance_sum_1c1',\n",
    "     'volume_imbalance_sum_3c1',\n",
    "     'volume_imbalance_sum_4c1',\n",
    "     'volume_imbalance_sum_6c1',       \n",
    "     'bid_ask_spread_sum_0c1',\n",
    "     'bid_ask_spread_sum_1c1',\n",
    "     'bid_ask_spread_sum_3c1',\n",
    "     'bid_ask_spread_sum_4c1',\n",
    "     'bid_ask_spread_sum_6c1',\n",
    "     'size_tau2_0c1',\n",
    "     'size_tau2_1c1',\n",
    "     'size_tau2_3c1',\n",
    "     'size_tau2_4c1',\n",
    "     'size_tau2_6c1'] \n",
    "print(mat1)\n",
    "train = pd.merge(train,mat1[nnn],how='left',on='time_id')\n",
    "test = pd.merge(test,mat2[nnn],how='left',on='time_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01815f31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T14:38:08.868713Z",
     "iopub.status.busy": "2023-12-13T14:38:08.867975Z",
     "iopub.status.idle": "2023-12-13T14:38:08.870929Z",
     "shell.execute_reply": "2023-12-13T14:38:08.871402Z",
     "shell.execute_reply.started": "2023-12-13T08:08:09.855689Z"
    },
    "papermill": {
     "duration": 0.140211,
     "end_time": "2023-12-13T14:38:08.871561",
     "exception": false,
     "start_time": "2023-12-13T14:38:08.731350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "732"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del mat1,mat2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c128e25f",
   "metadata": {
    "papermill": {
     "duration": 0.037633,
     "end_time": "2023-12-13T14:38:08.946759",
     "exception": false,
     "start_time": "2023-12-13T14:38:08.909126",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd0eae33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T14:38:09.030230Z",
     "iopub.status.busy": "2023-12-13T14:38:09.029541Z",
     "iopub.status.idle": "2023-12-13T14:38:09.032302Z",
     "shell.execute_reply": "2023-12-13T14:38:09.031699Z",
     "shell.execute_reply.started": "2023-12-13T08:08:09.955188Z"
    },
    "papermill": {
     "duration": 0.048369,
     "end_time": "2023-12-13T14:38:09.032455",
     "exception": false,
     "start_time": "2023-12-13T14:38:08.984086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "USE_PRECOMPUTE_FEATURES = True  # Load precomputed features for train.csv from private dataset (just for speed up)\n",
    "\n",
    "# model & ensemble configurations\n",
    "PREDICT_CNN = True\n",
    "PREDICT_MLP = True\n",
    "PREDICT_GBDT = True\n",
    "PREDICT_TABNET = False\n",
    "\n",
    "GBDT_NUM_MODELS = 5 #3\n",
    "GBDT_LR = 0.02  # 0.1\n",
    "\n",
    "NN_VALID_TH = 0.185\n",
    "NN_MODEL_TOP_N = 3\n",
    "TAB_MODEL_TOP_N = 3\n",
    "ENSEMBLE_METHOD = 'mean'\n",
    "NN_NUM_MODELS = 10\n",
    "TABNET_NUM_MODELS = 5\n",
    "\n",
    "# for saving quota\n",
    "IS_1ST_STAGE = False\n",
    "SHORTCUT_NN_IN_1ST_STAGE = True  # early-stop training to save GPU quota\n",
    "SHORTCUT_GBDT_IN_1ST_STAGE = False\n",
    "MEMORY_TEST_MODE = False\n",
    "\n",
    "# for ablation studies\n",
    "CV_SPLIT = 'time'  # 'time': time-series KFold 'group': GroupKFold by stock-id\n",
    "USE_PRICE_NN_FEATURES = True  # Use nearest neighbor features that rely on tick size\n",
    "USE_VOL_NN_FEATURES = True  # Use nearest neighbor features that can be calculated without tick size\n",
    "USE_SIZE_NN_FEATURES = True  # Use nearest neighbor features that can be calculated without tick size\n",
    "USE_RANDOM_NN_FEATURES = False  # Use random index to aggregate neighbors\n",
    "\n",
    "USE_TIME_ID_NN = True  # Use time-id based neighbors\n",
    "USE_STOCK_ID_NN = True  # Use stock-id based neighbors\n",
    "\n",
    "ENABLE_RANK_NORMALIZATION = True  # Enable rank-normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfc00283",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T14:38:09.144826Z",
     "iopub.status.busy": "2023-12-13T14:38:09.118536Z",
     "iopub.status.idle": "2023-12-13T14:38:10.807590Z",
     "shell.execute_reply": "2023-12-13T14:38:10.806857Z",
     "shell.execute_reply.started": "2023-12-13T08:08:09.965200Z"
    },
    "papermill": {
     "duration": 1.736274,
     "end_time": "2023-12-13T14:38:10.807751",
     "exception": false,
     "start_time": "2023-12-13T14:38:09.071477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import random\n",
    "from typing import List, Tuple, Optional, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.decomposition import PCA\n",
    "from pytorch_tabnet.metrics import Metric\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "null_check_cols = [\n",
    "    'book.log_return1.realized_volatility',\n",
    "    'book_150.log_return1.realized_volatility',\n",
    "    'book_300.log_return1.realized_volatility',\n",
    "    'book_450.log_return1.realized_volatility',\n",
    "    'trade.log_return.realized_volatility',\n",
    "    'trade_150.log_return.realized_volatility',\n",
    "    'trade_300.log_return.realized_volatility',\n",
    "    'trade_450.log_return.realized_volatility'\n",
    "] # might be problems in these columns\n",
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "def rmspe_metric(y_true, y_pred):\n",
    "    rmspe = np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "    return rmspe\n",
    "\n",
    "\n",
    "def rmspe_loss(y_true, y_pred):\n",
    "    rmspe = torch.sqrt(torch.mean(torch.square((y_true - y_pred) / y_true)))\n",
    "    return rmspe\n",
    "\n",
    "\n",
    "class RMSPE(Metric):\n",
    "    def __init__(self):\n",
    "        self._name = \"rmspe\"\n",
    "        self._maximize = False\n",
    "\n",
    "    def __call__(self, y_true, y_score):\n",
    "        return np.sqrt(np.mean(np.square((y_true - y_score) / y_true)))\n",
    "\n",
    "def RMSPELoss_Tabnet(y_pred, y_true):\n",
    "    return torch.sqrt(torch.mean( ((y_true - y_pred) / y_true) ** 2 )).clone()\n",
    "\n",
    "\n",
    "class AverageMeter:\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, x_num: np.ndarray, x_cat: np.ndarray, y: Optional[np.ndarray]):\n",
    "        super().__init__()\n",
    "        self.x_num = x_num\n",
    "        self.x_cat = x_cat\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_num)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is None:\n",
    "            return self.x_num[idx], torch.LongTensor(self.x_cat[idx])\n",
    "        else:\n",
    "            return self.x_num[idx], torch.LongTensor(self.x_cat[idx]), self.y[idx]\n",
    "\n",
    "\n",
    "class MLP(nn.Module): \n",
    "    def __init__(self,\n",
    "                 src_num_dim: int,\n",
    "                 n_categories: List[int],\n",
    "                 dropout: float = 0.0,\n",
    "                 hidden: int = 50,\n",
    "                 emb_dim: int = 10,\n",
    "                 dropout_cat: float = 0.2,\n",
    "                 bn: bool = False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embs = nn.ModuleList([\n",
    "            nn.Embedding(x, emb_dim) for x in n_categories])\n",
    "        self.cat_dim = emb_dim * len(n_categories)\n",
    "        self.dropout_cat = nn.Dropout(dropout_cat)\n",
    "\n",
    "        if bn:\n",
    "            self.sequence = nn.Sequential(\n",
    "                nn.Linear(src_num_dim + self.cat_dim, hidden),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.BatchNorm1d(hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden, hidden),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.BatchNorm1d(hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden, 1)\n",
    "            )\n",
    "        else:\n",
    "            self.sequence = nn.Sequential(\n",
    "                nn.Linear(src_num_dim + self.cat_dim, hidden),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden, hidden),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden, 1)\n",
    "            )\n",
    "\n",
    "    def forward(self, x_num, x_cat):\n",
    "        embs = [embedding(x_cat[:, i]) for i, embedding in enumerate(self.embs)]\n",
    "        x_cat_emb = self.dropout_cat(torch.cat(embs, 1))\n",
    "        x_all = torch.cat([x_num, x_cat_emb], 1)\n",
    "        x = self.sequence(x_all)\n",
    "        return torch.squeeze(x)\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_features: int,\n",
    "                 hidden_size: int,\n",
    "                 n_categories: List[int],\n",
    "                 emb_dim: int = 10,\n",
    "                 dropout_cat: float = 0.2,\n",
    "                 channel_1: int = 256,\n",
    "                 channel_2: int = 512,\n",
    "                 channel_3: int = 512,\n",
    "                 dropout_top: float = 0.1,\n",
    "                 dropout_mid: float = 0.3,\n",
    "                 dropout_bottom: float = 0.2,\n",
    "                 weight_norm: bool = True,\n",
    "                 two_stage: bool = True,\n",
    "                 celu: bool = True,\n",
    "                 kernel1: int = 5,\n",
    "                 leaky_relu: bool = False):\n",
    "        super().__init__()\n",
    "\n",
    "        num_targets = 1\n",
    "\n",
    "        cha_1_reshape = int(hidden_size / channel_1)\n",
    "        cha_po_1 = int(hidden_size / channel_1 / 2)\n",
    "        cha_po_2 = int(hidden_size / channel_1 / 2 / 2) * channel_3\n",
    "\n",
    "        self.cat_dim = emb_dim * len(n_categories)\n",
    "        self.cha_1 = channel_1\n",
    "        self.cha_2 = channel_2\n",
    "        self.cha_3 = channel_3\n",
    "        self.cha_1_reshape = cha_1_reshape\n",
    "        self.cha_po_1 = cha_po_1\n",
    "        self.cha_po_2 = cha_po_2\n",
    "        self.two_stage = two_stage\n",
    "\n",
    "        self.expand = nn.Sequential(\n",
    "            nn.BatchNorm1d(num_features + self.cat_dim),\n",
    "            nn.Dropout(dropout_top),\n",
    "            nn.utils.weight_norm(nn.Linear(num_features + self.cat_dim, hidden_size), dim=None),\n",
    "            nn.CELU(0.06) if celu else nn.ReLU()\n",
    "        )\n",
    "\n",
    "        def _norm(layer, dim=None):\n",
    "            return nn.utils.weight_norm(layer, dim=dim) if weight_norm else layer\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.BatchNorm1d(channel_1),\n",
    "            nn.Dropout(dropout_top),\n",
    "            _norm(nn.Conv1d(channel_1, channel_2, kernel_size=kernel1, stride=1, padding=kernel1 // 2, bias=False)),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(output_size=cha_po_1),\n",
    "            nn.BatchNorm1d(channel_2),\n",
    "            nn.Dropout(dropout_top),\n",
    "            _norm(nn.Conv1d(channel_2, channel_2, kernel_size=3, stride=1, padding=1, bias=True)),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        if self.two_stage:\n",
    "            self.conv2 = nn.Sequential(\n",
    "                nn.BatchNorm1d(channel_2),\n",
    "                nn.Dropout(dropout_mid),\n",
    "                _norm(nn.Conv1d(channel_2, channel_2, kernel_size=3, stride=1, padding=1, bias=True)),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm1d(channel_2),\n",
    "                nn.Dropout(dropout_bottom),\n",
    "                _norm(nn.Conv1d(channel_2, channel_3, kernel_size=5, stride=1, padding=2, bias=True)),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "\n",
    "        self.max_po_c2 = nn.MaxPool1d(kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "        self.flt = nn.Flatten()\n",
    "\n",
    "        if leaky_relu:\n",
    "            self.dense = nn.Sequential(\n",
    "                nn.BatchNorm1d(cha_po_2),\n",
    "                nn.Dropout(dropout_bottom),\n",
    "                _norm(nn.Linear(cha_po_2, num_targets), dim=0),\n",
    "                nn.LeakyReLU()\n",
    "            )\n",
    "        else:\n",
    "            self.dense = nn.Sequential(\n",
    "                nn.BatchNorm1d(cha_po_2),\n",
    "                nn.Dropout(dropout_bottom),\n",
    "                _norm(nn.Linear(cha_po_2, num_targets), dim=0)\n",
    "            )\n",
    "\n",
    "        self.embs = nn.ModuleList([nn.Embedding(x, emb_dim) for x in n_categories])\n",
    "        self.cat_dim = emb_dim * len(n_categories)\n",
    "        self.dropout_cat = nn.Dropout(dropout_cat)\n",
    "\n",
    "    def forward(self, x_num, x_cat):\n",
    "        embs = [embedding(x_cat[:, i]) for i, embedding in enumerate(self.embs)]\n",
    "        x_cat_emb = self.dropout_cat(torch.cat(embs, 1))\n",
    "        x = torch.cat([x_num, x_cat_emb], 1)\n",
    "\n",
    "        x = self.expand(x)\n",
    "\n",
    "        x = x.reshape(x.shape[0], self.cha_1, self.cha_1_reshape)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        if self.two_stage:\n",
    "            x = self.conv2(x) * x\n",
    "\n",
    "        x = self.max_po_c2(x)\n",
    "        x = self.flt(x)\n",
    "        x = self.dense(x)\n",
    "\n",
    "        return torch.squeeze(x)\n",
    "\n",
    "\n",
    "def preprocess_nn(\n",
    "        X: pd.DataFrame,\n",
    "        scaler: Optional[StandardScaler] = None,\n",
    "        scaler_type: str = 'standard',\n",
    "        n_pca: int = -1,\n",
    "        na_cols: bool = True):\n",
    "    if na_cols:\n",
    "        #for c in X.columns:\n",
    "        for c in null_check_cols:\n",
    "            if c in X.columns:\n",
    "                X[f\"{c}_isnull\"] = X[c].isnull().astype(int)\n",
    "\n",
    "    cat_cols = [c for c in X.columns if c in ['time_id', 'stock_id']]\n",
    "    num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "    X_num = X[num_cols].values.astype(np.float32)\n",
    "    X_cat = np.nan_to_num(X[cat_cols].values.astype(np.int32))\n",
    "\n",
    "    def _pca(X_num_):\n",
    "        if n_pca > 0:\n",
    "            pca = PCA(n_components=n_pca, random_state=0)\n",
    "            return pca.fit_transform(X_num)\n",
    "        return X_num\n",
    "\n",
    "    if scaler is None:\n",
    "        scaler = StandardScaler()\n",
    "        X_num = scaler.fit_transform(X_num)\n",
    "        X_num = np.nan_to_num(X_num, posinf=0, neginf=0)\n",
    "        return _pca(X_num), X_cat, cat_cols, scaler\n",
    "    else:\n",
    "        X_num = scaler.transform(X_num) #TODO: infでも大丈夫？\n",
    "        X_num = np.nan_to_num(X_num, posinf=0, neginf=0)\n",
    "        return _pca(X_num), X_cat, cat_cols\n",
    "\n",
    "\n",
    "def train_epoch(data_loader: DataLoader,\n",
    "                model: nn.Module,\n",
    "                optimizer,\n",
    "                scheduler,\n",
    "                device,\n",
    "                clip_grad: float = 1.5):\n",
    "    model.train()\n",
    "    losses = AverageMeter()\n",
    "    step = 0\n",
    "\n",
    "    for x_num, x_cat, y in tqdm(data_loader, position=0, leave=True, desc='Training'):\n",
    "        batch_size = x_num.size(0)\n",
    "        x_num = x_num.to(device, dtype=torch.float)\n",
    "        x_cat = x_cat.to(device)\n",
    "        y = y.to(device, dtype=torch.float)\n",
    "\n",
    "        loss = rmspe_loss(y, model(x_num, x_cat))\n",
    "        losses.update(loss.detach().cpu().numpy(), batch_size)\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        step += 1\n",
    "\n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def evaluate(data_loader: DataLoader, model, device):\n",
    "    model.eval()\n",
    "\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    final_targets = []\n",
    "    final_outputs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_num, x_cat, y in tqdm(data_loader, position=0, leave=True, desc='Evaluating'):\n",
    "            batch_size = x_num.size(0)\n",
    "            x_num = x_num.to(device, dtype=torch.float)\n",
    "            x_cat = x_cat.to(device)\n",
    "            y = y.to(device, dtype=torch.float)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = model(x_num, x_cat)\n",
    "\n",
    "            loss = rmspe_loss(y, output)\n",
    "            # record loss\n",
    "            losses.update(loss.detach().cpu().numpy(), batch_size)\n",
    "\n",
    "            targets = y.detach().cpu().numpy()\n",
    "            output = output.detach().cpu().numpy()\n",
    "\n",
    "            final_targets.append(targets)\n",
    "            final_outputs.append(output)\n",
    "\n",
    "    final_targets = np.concatenate(final_targets)\n",
    "    final_outputs = np.concatenate(final_outputs)\n",
    "\n",
    "    try:\n",
    "        metric = rmspe_metric(final_targets, final_outputs)\n",
    "    except:\n",
    "        metric = None\n",
    "\n",
    "    return final_outputs, final_targets, losses.avg, metric\n",
    "\n",
    "\n",
    "def predict_nn(X: pd.DataFrame,\n",
    "               model: Union[List[MLP], MLP],\n",
    "               scaler: StandardScaler,\n",
    "               device,\n",
    "               ensemble_method='mean'):\n",
    "    if not isinstance(model, list):\n",
    "        model = [model]\n",
    "\n",
    "    for m in model:\n",
    "        m.eval()\n",
    "    X_num, X_cat, cat_cols = preprocess_nn(X.copy(), scaler=scaler)\n",
    "    valid_dataset = TabularDataset(X_num, X_cat, None)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                               batch_size=512,\n",
    "                                               shuffle=False,\n",
    "                                               num_workers=4)\n",
    "\n",
    "    final_outputs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_num, x_cat in tqdm(valid_loader, position=0, leave=True, desc='Evaluating'):\n",
    "            x_num = x_num.to(device, dtype=torch.float)\n",
    "            x_cat = x_cat.to(device)\n",
    "\n",
    "            outputs = []\n",
    "            with torch.no_grad():\n",
    "                for m in model:\n",
    "                    output = m(x_num, x_cat)\n",
    "                    outputs.append(output.detach().cpu().numpy())\n",
    "\n",
    "            if ensemble_method == 'median':\n",
    "                pred = np.nanmedian(np.array(outputs), axis=0)\n",
    "            else:\n",
    "                pred = np.array(outputs).mean(axis=0)\n",
    "            final_outputs.append(pred)\n",
    "\n",
    "    final_outputs = np.concatenate(final_outputs)\n",
    "    return final_outputs\n",
    "\n",
    "\n",
    "def predict_tabnet(X: pd.DataFrame,\n",
    "                   model: Union[List[TabNetRegressor], TabNetRegressor],\n",
    "                   scaler: StandardScaler,\n",
    "                   ensemble_method='mean'):\n",
    "    if not isinstance(model, list):\n",
    "        model = [model]\n",
    "\n",
    "    X_num, X_cat, cat_cols = preprocess_nn(X.copy(), scaler=scaler)\n",
    "    X_processed = np.concatenate([X_cat, X_num], axis=1)\n",
    "\n",
    "    predicted = []\n",
    "    for m in model:\n",
    "        predicted.append(m.predict(X_processed))\n",
    "\n",
    "    if ensemble_method == 'median':\n",
    "        pred = np.nanmedian(np.array(predicted), axis=0)\n",
    "    else:\n",
    "        pred = np.array(predicted).mean(axis=0)\n",
    "\n",
    "    return pred\n",
    "\n",
    "\n",
    "def train_tabnet(X: pd.DataFrame,\n",
    "                 y: pd.DataFrame,\n",
    "                 #folds: List[Tuple],\n",
    "                 batch_size: int = 1024,\n",
    "                 lr: float = 1e-3,\n",
    "                 model_path: str = 'fold_{}.pth',\n",
    "                 scaler_type: str = 'standard',\n",
    "                 output_dir: str = 'artifacts',\n",
    "                 epochs: int = 250,\n",
    "                 seed: int = 42,\n",
    "                 n_pca: int = -1,\n",
    "                 na_cols: bool = True,\n",
    "                 patience: int = 10,\n",
    "                 factor: float = 0.5,\n",
    "                 gamma: float = 2.0,\n",
    "                 lambda_sparse: float = 8.0,\n",
    "                 n_steps: int = 2,\n",
    "                 scheduler_type: str = 'cosine',\n",
    "                 n_a: int = 16):\n",
    "    seed_everything(seed)\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    y = y.values.astype(np.float32)\n",
    "    X_num, X_cat, cat_cols, scaler = preprocess_nn(X.copy(), scaler_type=scaler_type, n_pca=n_pca, na_cols=na_cols)\n",
    "\n",
    "    best_losses = []\n",
    "    best_predictions = []\n",
    "    kfold = KFold(n_splits = 3, random_state = 2021, shuffle = True)\n",
    "    for cv_idx, (train_idx, valid_idx) in enumerate(kfold.split(train)):\n",
    "        X_tr, X_va = X_num[train_idx], X_num[valid_idx]\n",
    "        X_tr_cat, X_va_cat = X_cat[train_idx], X_cat[valid_idx]\n",
    "        y_tr, y_va = y[train_idx], y[valid_idx]\n",
    "        y_tr = y_tr.reshape(-1,1)\n",
    "        y_va = y_va.reshape(-1,1)\n",
    "        X_tr = np.concatenate([X_tr_cat, X_tr], axis=1)\n",
    "        X_va = np.concatenate([X_va_cat, X_va], axis=1)\n",
    "\n",
    "        cat_idxs = [0]\n",
    "        cat_dims = [128]\n",
    "\n",
    "        if scheduler_type == 'cosine':\n",
    "            scheduler_params = dict(T_0=200, T_mult=1, eta_min=1e-4, last_epoch=-1, verbose=False)\n",
    "            scheduler_fn = CosineAnnealingWarmRestarts\n",
    "        else:\n",
    "            scheduler_params = {'mode': 'min', 'min_lr': 1e-7, 'patience': patience, 'factor': factor, 'verbose': True}\n",
    "            scheduler_fn = torch.optim.lr_scheduler.ReduceLROnPlateau\n",
    "\n",
    "        model = TabNetRegressor(\n",
    "            cat_idxs=cat_idxs,\n",
    "            cat_dims=cat_dims,\n",
    "            cat_emb_dim=1,\n",
    "            n_d=n_a,\n",
    "            n_a=n_a,\n",
    "            n_steps=n_steps,\n",
    "            gamma=gamma,\n",
    "            n_independent=2,\n",
    "            n_shared=2,\n",
    "            lambda_sparse=lambda_sparse,\n",
    "            optimizer_fn=torch.optim.Adam,\n",
    "            optimizer_params={'lr': lr},\n",
    "            mask_type=\"entmax\",\n",
    "            scheduler_fn=scheduler_fn,\n",
    "            scheduler_params=scheduler_params,\n",
    "            seed=seed,\n",
    "            verbose=10\n",
    "            #device_name=device,\n",
    "            #clip_value=1.5\n",
    "        )\n",
    "\n",
    "        model.fit(X_tr, y_tr, eval_set=[(X_va, y_va)], max_epochs=epochs, patience=50, batch_size=1024*20,\n",
    "                  virtual_batch_size=batch_size, num_workers=4, drop_last=False, eval_metric=[RMSPE], loss_fn=RMSPELoss_Tabnet)\n",
    "\n",
    "        path = os.path.join(output_dir, model_path.format(cv_idx))\n",
    "        model.save_model(path)\n",
    "\n",
    "        predicted = model.predict(X_va)\n",
    "\n",
    "        rmspe = rmspe_metric(y_va, predicted)\n",
    "        best_losses.append(rmspe)\n",
    "        best_predictions.append(predicted)\n",
    "\n",
    "    return best_losses, best_predictions, scaler, model\n",
    "\n",
    "\n",
    "def train_nn(X: pd.DataFrame,\n",
    "             y: pd.DataFrame,\n",
    "             #folds: List[Tuple],\n",
    "             device,\n",
    "             emb_dim: int = 25,\n",
    "             batch_size: int = 1024,\n",
    "             model_type: str = 'mlp',\n",
    "             mlp_dropout: float = 0.0,\n",
    "             mlp_hidden: int = 64,\n",
    "             mlp_bn: bool = False,\n",
    "             cnn_hidden: int = 64,\n",
    "             cnn_channel1: int = 32,\n",
    "             cnn_channel2: int = 32,\n",
    "             cnn_channel3: int = 32,\n",
    "             cnn_kernel1: int = 5,\n",
    "             cnn_celu: bool = False,\n",
    "             cnn_weight_norm: bool = False,\n",
    "             dropout_emb: bool = 0.0,\n",
    "             lr: float = 1e-3,\n",
    "             weight_decay: float = 0.0,\n",
    "             model_path: str = 'fold_{}.pth',\n",
    "             scaler_type: str = 'standard',\n",
    "             output_dir: str = 'artifacts',\n",
    "             scheduler_type: str = 'onecycle',\n",
    "             optimizer_type: str = 'adam',\n",
    "             max_lr: float = 0.01,\n",
    "             epochs: int = 30,\n",
    "             seed: int = 42,\n",
    "             n_pca: int = 100,\n",
    "             batch_double_freq: int = 50,\n",
    "             cnn_dropout: float = 0.1,\n",
    "             na_cols: bool = True,\n",
    "             cnn_leaky_relu: bool = False,\n",
    "             patience: int = 8,\n",
    "             factor: float = 0.5):\n",
    "    seed_everything(seed)\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    y = y.values.astype(np.float32)\n",
    "    X_num, X_cat, cat_cols, scaler = preprocess_nn(X.copy(), scaler_type=scaler_type, n_pca=n_pca, na_cols=na_cols)\n",
    "\n",
    "    best_losses = []\n",
    "    best_predictions = []\n",
    "    kfold = KFold(n_splits = 5, random_state = 2021, shuffle = True)\n",
    "    # Iterate through each fold\n",
    "    \n",
    "    for cv_idx, (train_idx, valid_idx) in enumerate(kfold.split(train)):\n",
    "        X_tr, X_va = X_num[train_idx], X_num[valid_idx]\n",
    "        X_tr_cat, X_va_cat = X_cat[train_idx], X_cat[valid_idx]\n",
    "        y_tr, y_va = y[train_idx], y[valid_idx]\n",
    "\n",
    "        cur_batch = batch_size\n",
    "        best_loss = 1e10\n",
    "        best_prediction = None\n",
    "\n",
    "        print(f\"fold {cv_idx} train: {X_tr.shape}, valid: {X_va.shape}\")\n",
    "\n",
    "        train_dataset = TabularDataset(X_tr, X_tr_cat, y_tr)\n",
    "        valid_dataset = TabularDataset(X_va, X_va_cat, y_va)\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=cur_batch, shuffle=True,\n",
    "                                                   num_workers=4)\n",
    "        valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=cur_batch, shuffle=False,\n",
    "                                                   num_workers=4)\n",
    "\n",
    "        if model_type == 'mlp':\n",
    "            model = MLP(X_tr.shape[1],\n",
    "                        n_categories=[128],\n",
    "                        dropout=mlp_dropout, hidden=mlp_hidden, emb_dim=emb_dim,\n",
    "                        dropout_cat=dropout_emb, bn=mlp_bn)\n",
    "        elif model_type == 'cnn':\n",
    "            model = CNN(X_tr.shape[1],\n",
    "                        hidden_size=cnn_hidden,\n",
    "                        n_categories=[128],\n",
    "                        emb_dim=emb_dim,\n",
    "                        dropout_cat=dropout_emb,\n",
    "                        channel_1=cnn_channel1,\n",
    "                        channel_2=cnn_channel2,\n",
    "                        channel_3=cnn_channel3,\n",
    "                        two_stage=False,\n",
    "                        kernel1=cnn_kernel1,\n",
    "                        celu=cnn_celu,\n",
    "                        dropout_top=cnn_dropout,\n",
    "                        dropout_mid=cnn_dropout,\n",
    "                        dropout_bottom=cnn_dropout,\n",
    "                        weight_norm=cnn_weight_norm,\n",
    "                        leaky_relu=cnn_leaky_relu)\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "        model = model.to(device)\n",
    "\n",
    "        if optimizer_type == 'adamw':\n",
    "            opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        elif optimizer_type == 'adam':\n",
    "            opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "        scheduler = epoch_scheduler = None\n",
    "        if scheduler_type == 'onecycle':\n",
    "            scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer=opt, pct_start=0.1, div_factor=1e3,\n",
    "                                                            max_lr=max_lr, epochs=epochs,\n",
    "                                                            steps_per_epoch=len(train_loader))\n",
    "        elif scheduler_type == 'reduce':\n",
    "            epoch_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=opt,\n",
    "                                                                         mode='min',\n",
    "                                                                         min_lr=1e-7,\n",
    "                                                                         patience=patience,\n",
    "                                                                         verbose=True,\n",
    "                                                                         factor=factor)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            if epoch > 0 and epoch % batch_double_freq == 0:\n",
    "                cur_batch = cur_batch * 2\n",
    "                print(f'batch: {cur_batch}')\n",
    "                train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                           batch_size=cur_batch,\n",
    "                                                           shuffle=True,\n",
    "                                                           num_workers=4)\n",
    "            train_loss = train_epoch(train_loader, model, opt, scheduler, device)\n",
    "            predictions, valid_targets, valid_loss, rmspe = evaluate(valid_loader, model, device=device)\n",
    "            print(f\"epoch {epoch}, train loss: {train_loss:.3f}, valid rmspe: {rmspe:.3f}\")\n",
    "\n",
    "            if epoch_scheduler is not None:\n",
    "                epoch_scheduler.step(rmspe)\n",
    "\n",
    "            if rmspe < best_loss:\n",
    "                print(f'new best:{rmspe}')\n",
    "                best_loss = rmspe\n",
    "                best_prediction = predictions\n",
    "                torch.save(model, os.path.join(output_dir, model_path.format(cv_idx)))\n",
    "\n",
    "        best_predictions.append(best_prediction)\n",
    "        best_losses.append(best_loss)\n",
    "        del model, train_dataset, valid_dataset, train_loader, valid_loader, X_tr, X_va, X_tr_cat, X_va_cat, y_tr, y_va, opt\n",
    "        if scheduler is not None:\n",
    "            del scheduler\n",
    "        gc.collect()\n",
    "\n",
    "    return best_losses, best_predictions, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3de7886",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T14:38:11.017268Z",
     "iopub.status.busy": "2023-12-13T14:38:11.012216Z",
     "iopub.status.idle": "2023-12-13T17:00:12.522369Z",
     "shell.execute_reply": "2023-12-13T17:00:12.521751Z",
     "shell.execute_reply.started": "2023-12-13T08:08:11.588546Z"
    },
    "papermill": {
     "duration": 8521.675946,
     "end_time": "2023-12-13T17:00:12.522516",
     "exception": false,
     "start_time": "2023-12-13T14:38:10.846570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "cuda\n",
      "fold 0 train: (343145, 100), valid: (85787, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:09<00:00, 27.74it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 59.69it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss: 80.994, valid rmspe: 33.618\n",
      "new best:33.61837387084961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:07<00:00, 33.65it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.55it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss: 20.507, valid rmspe: 10.534\n",
      "new best:10.533888816833496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.22it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.07it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, train loss: 12.493, valid rmspe: 17.430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:07<00:00, 34.06it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.04it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, train loss: 8.601, valid rmspe: 4.377\n",
      "new best:4.376883029937744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:07<00:00, 33.66it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 59.22it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, train loss: 6.961, valid rmspe: 4.709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:07<00:00, 33.79it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 45.64it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, train loss: 6.008, valid rmspe: 2.181\n",
      "new best:2.1809237003326416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:07<00:00, 33.71it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 60.21it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, train loss: 5.443, valid rmspe: 9.178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.45it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.80it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, train loss: 3.227, valid rmspe: 3.426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:07<00:00, 33.78it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 53.17it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, train loss: 2.842, valid rmspe: 1.292\n",
      "new best:1.2918000221252441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.88it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.82it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, train loss: 1.695, valid rmspe: 4.140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.12it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 53.17it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, train loss: 1.316, valid rmspe: 0.551\n",
      "new best:0.5512531995773315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.97it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.71it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, train loss: 0.867, valid rmspe: 0.949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.62it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.69it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, train loss: 0.747, valid rmspe: 1.029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.63it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.13it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, train loss: 0.851, valid rmspe: 0.654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.46it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.79it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, train loss: 0.633, valid rmspe: 0.416\n",
      "new best:0.41565173864364624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.76it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 52.13it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, train loss: 0.491, valid rmspe: 1.363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.85it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.78it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, train loss: 0.410, valid rmspe: 0.755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.91it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.23it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, train loss: 0.406, valid rmspe: 0.322\n",
      "new best:0.3224969804286957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.26it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.10it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, train loss: 0.322, valid rmspe: 0.236\n",
      "new best:0.23593057692050934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.51it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.76it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, train loss: 0.346, valid rmspe: 0.302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.83it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.78it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, train loss: 0.333, valid rmspe: 0.242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.71it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.67it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21, train loss: 0.278, valid rmspe: 0.243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.11it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.89it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22, train loss: 0.287, valid rmspe: 0.230\n",
      "new best:0.23034866154193878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.72it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 51.09it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23, train loss: 0.254, valid rmspe: 0.318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.03it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.92it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24, train loss: 0.236, valid rmspe: 0.234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.33it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 49.37it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25, train loss: 0.230, valid rmspe: 0.223\n",
      "new best:0.22339491546154022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.07it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.59it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26, train loss: 0.225, valid rmspe: 0.221\n",
      "new best:0.22067438066005707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.87it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.17it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27, train loss: 0.217, valid rmspe: 0.231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.23it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.94it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28, train loss: 0.218, valid rmspe: 0.211\n",
      "new best:0.21050873398780823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.59it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.25it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29, train loss: 0.211, valid rmspe: 0.265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.81it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.98it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30, train loss: 0.216, valid rmspe: 0.214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.37it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.58it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31, train loss: 0.221, valid rmspe: 0.234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.59it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.04it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32, train loss: 0.222, valid rmspe: 0.211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.14it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 48.15it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33, train loss: 0.214, valid rmspe: 0.222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.95it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.08it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34, train loss: 0.208, valid rmspe: 0.219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.05it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.56it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35, train loss: 0.209, valid rmspe: 0.216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.30it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.49it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36, train loss: 0.213, valid rmspe: 0.285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.35it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.83it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37, train loss: 0.217, valid rmspe: 0.219\n",
      "Epoch    38: reducing learning rate of group 0 to 1.1400e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.15it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.19it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38, train loss: 0.199, valid rmspe: 0.207\n",
      "new best:0.20706097781658173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.75it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.07it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39, train loss: 0.196, valid rmspe: 0.209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.41it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.71it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40, train loss: 0.195, valid rmspe: 0.211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.15it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.86it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41, train loss: 0.198, valid rmspe: 0.224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.76it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.17it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42, train loss: 0.194, valid rmspe: 0.210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.42it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 49.49it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43, train loss: 0.192, valid rmspe: 0.213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.78it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.44it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44, train loss: 0.191, valid rmspe: 0.211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.49it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.26it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45, train loss: 0.190, valid rmspe: 0.208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.09it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 59.32it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46, train loss: 0.190, valid rmspe: 0.213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.70it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.96it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47, train loss: 0.191, valid rmspe: 0.210\n",
      "Epoch    48: reducing learning rate of group 0 to 3.4200e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.19it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.86it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48, train loss: 0.184, valid rmspe: 0.214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.48it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.24it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49, train loss: 0.183, valid rmspe: 0.207\n",
      "fold 1 train: (343145, 100), valid: (85787, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.36it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.63it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss: 58.724, valid rmspe: 25.453\n",
      "new best:25.452754974365234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.03it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.54it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss: 14.616, valid rmspe: 6.105\n",
      "new best:6.104581356048584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.53it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 55.65it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, train loss: 13.201, valid rmspe: 28.466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.94it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.80it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, train loss: 10.074, valid rmspe: 6.810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.01it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.87it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, train loss: 6.505, valid rmspe: 3.898\n",
      "new best:3.898336410522461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.78it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.71it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, train loss: 6.792, valid rmspe: 4.790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.61it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.65it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, train loss: 4.490, valid rmspe: 6.562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.15it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.89it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, train loss: 3.464, valid rmspe: 2.167\n",
      "new best:2.1672487258911133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.13it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.18it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, train loss: 1.893, valid rmspe: 1.292\n",
      "new best:1.291668176651001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.79it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.03it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, train loss: 1.353, valid rmspe: 1.008\n",
      "new best:1.007637619972229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.28it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 46.29it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, train loss: 0.832, valid rmspe: 0.324\n",
      "new best:0.3241455852985382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.05it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.07it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, train loss: 0.401, valid rmspe: 0.270\n",
      "new best:0.27011922001838684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.75it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.74it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, train loss: 0.255, valid rmspe: 0.225\n",
      "new best:0.2254498302936554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.87it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.32it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, train loss: 0.244, valid rmspe: 0.229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.74it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.41it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, train loss: 0.236, valid rmspe: 0.237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.03it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.27it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, train loss: 0.230, valid rmspe: 0.221\n",
      "new best:0.22105860710144043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.15it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.81it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, train loss: 0.226, valid rmspe: 0.212\n",
      "new best:0.2123938351869583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.33it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 48.56it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, train loss: 0.227, valid rmspe: 0.222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.93it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.58it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, train loss: 0.221, valid rmspe: 0.214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.63it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.63it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, train loss: 0.220, valid rmspe: 0.222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.03it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.26it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, train loss: 0.228, valid rmspe: 0.244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.36it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.08it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21, train loss: 0.217, valid rmspe: 0.212\n",
      "new best:0.21173375844955444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.60it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.58it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22, train loss: 0.217, valid rmspe: 0.212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.95it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.60it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23, train loss: 0.221, valid rmspe: 0.208\n",
      "new best:0.20808979868888855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 31.68it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 54.90it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24, train loss: 0.215, valid rmspe: 0.214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.08it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.09it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25, train loss: 0.217, valid rmspe: 0.210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.86it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.78it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26, train loss: 0.213, valid rmspe: 0.215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.31it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 55.45it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27, train loss: 0.214, valid rmspe: 0.209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.37it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.73it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28, train loss: 0.222, valid rmspe: 0.209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.72it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.94it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29, train loss: 0.214, valid rmspe: 0.228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.49it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.15it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30, train loss: 0.217, valid rmspe: 0.207\n",
      "new best:0.20730145275592804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.41it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 50.10it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31, train loss: 0.210, valid rmspe: 0.209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.52it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.24it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32, train loss: 0.213, valid rmspe: 0.220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.23it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 59.45it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33, train loss: 0.208, valid rmspe: 0.235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.23it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 54.95it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34, train loss: 0.209, valid rmspe: 0.210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.27it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.90it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35, train loss: 0.217, valid rmspe: 0.252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.64it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.53it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36, train loss: 0.212, valid rmspe: 0.216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.38it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.28it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37, train loss: 0.210, valid rmspe: 0.220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.57it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 46.98it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38, train loss: 0.214, valid rmspe: 0.214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.54it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.46it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39, train loss: 0.211, valid rmspe: 0.230\n",
      "Epoch    40: reducing learning rate of group 0 to 1.1400e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.02it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.84it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40, train loss: 0.199, valid rmspe: 0.208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.29it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 55.85it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41, train loss: 0.194, valid rmspe: 0.205\n",
      "new best:0.2049465775489807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 31.39it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.64it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42, train loss: 0.192, valid rmspe: 0.209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.41it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 53.53it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43, train loss: 0.192, valid rmspe: 0.201\n",
      "new best:0.2010989636182785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.14it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 55.17it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44, train loss: 0.190, valid rmspe: 0.202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.24it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 39.64it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45, train loss: 0.188, valid rmspe: 0.205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 31.80it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 54.93it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46, train loss: 0.185, valid rmspe: 0.223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.80it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 53.49it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47, train loss: 0.188, valid rmspe: 0.200\n",
      "new best:0.20033249258995056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.68it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.58it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48, train loss: 0.186, valid rmspe: 0.206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 30.71it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.34it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49, train loss: 0.184, valid rmspe: 0.203\n",
      "fold 2 train: (343146, 100), valid: (85786, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.70it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.21it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss: 62.350, valid rmspe: 51.997\n",
      "new best:51.99661636352539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.08it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.85it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss: 17.683, valid rmspe: 46.670\n",
      "new best:46.670021057128906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.04it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 47.90it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, train loss: 11.974, valid rmspe: 15.711\n",
      "new best:15.71083927154541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.13it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.65it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, train loss: 8.893, valid rmspe: 25.735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.72it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.58it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, train loss: 8.683, valid rmspe: 5.584\n",
      "new best:5.583968162536621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.98it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 46.35it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, train loss: 5.580, valid rmspe: 4.941\n",
      "new best:4.940836429595947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.10it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.06it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, train loss: 3.276, valid rmspe: 2.537\n",
      "new best:2.5365729331970215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.33it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.31it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, train loss: 3.340, valid rmspe: 7.291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.33it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.85it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, train loss: 2.743, valid rmspe: 2.688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.64it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 52.34it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, train loss: 1.953, valid rmspe: 1.662\n",
      "new best:1.6618080139160156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.40it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.24it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, train loss: 0.745, valid rmspe: 0.632\n",
      "new best:0.6324846148490906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.32it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.52it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, train loss: 0.458, valid rmspe: 0.381\n",
      "new best:0.380692720413208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.62it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.79it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, train loss: 0.313, valid rmspe: 0.336\n",
      "new best:0.336494117975235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 31.98it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 49.28it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, train loss: 0.256, valid rmspe: 0.305\n",
      "new best:0.304878294467926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.38it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.76it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, train loss: 0.240, valid rmspe: 0.247\n",
      "new best:0.24653570353984833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.92it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 50.13it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, train loss: 0.231, valid rmspe: 0.232\n",
      "new best:0.23197360336780548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.48it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 55.57it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, train loss: 0.231, valid rmspe: 0.258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.26it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.31it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, train loss: 0.225, valid rmspe: 0.305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.43it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.77it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, train loss: 0.222, valid rmspe: 0.235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.71it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 59.17it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, train loss: 0.221, valid rmspe: 0.234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.05it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 45.43it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, train loss: 0.218, valid rmspe: 0.240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 31.10it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.06it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21, train loss: 0.236, valid rmspe: 0.234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 31.96it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 55.78it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22, train loss: 0.220, valid rmspe: 0.231\n",
      "new best:0.23138292133808136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.77it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.32it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23, train loss: 0.221, valid rmspe: 0.215\n",
      "new best:0.21489346027374268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 31.38it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.56it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24, train loss: 0.221, valid rmspe: 0.223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.06it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.60it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25, train loss: 0.217, valid rmspe: 0.233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.53it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 55.09it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26, train loss: 0.215, valid rmspe: 0.226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.59it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 52.31it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27, train loss: 0.212, valid rmspe: 0.228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 31.06it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 46.45it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28, train loss: 0.210, valid rmspe: 0.255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.35it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 55.34it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29, train loss: 0.210, valid rmspe: 0.229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.59it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 53.17it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30, train loss: 0.213, valid rmspe: 0.257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 30.44it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 44.76it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31, train loss: 0.215, valid rmspe: 0.225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 31.76it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.35it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32, train loss: 0.211, valid rmspe: 0.233\n",
      "Epoch    33: reducing learning rate of group 0 to 1.1400e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.61it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.89it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33, train loss: 0.202, valid rmspe: 0.221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.28it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 54.36it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34, train loss: 0.199, valid rmspe: 0.219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:09<00:00, 29.67it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 54.92it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35, train loss: 0.197, valid rmspe: 0.222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.19it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 53.84it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36, train loss: 0.195, valid rmspe: 0.216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 31.79it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 53.81it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37, train loss: 0.195, valid rmspe: 0.219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 31.05it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 44.00it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38, train loss: 0.193, valid rmspe: 0.217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 31.02it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 55.41it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39, train loss: 0.191, valid rmspe: 0.221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.07it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 54.25it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40, train loss: 0.191, valid rmspe: 0.217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.28it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 50.18it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41, train loss: 0.190, valid rmspe: 0.223\n",
      "Epoch    42: reducing learning rate of group 0 to 3.4200e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 30.92it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.73it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42, train loss: 0.184, valid rmspe: 0.213\n",
      "new best:0.21314366161823273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.87it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.13it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43, train loss: 0.183, valid rmspe: 0.218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.06it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.89it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44, train loss: 0.182, valid rmspe: 0.221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.31it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.49it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45, train loss: 0.181, valid rmspe: 0.222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 31.37it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 55.77it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46, train loss: 0.180, valid rmspe: 0.219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.87it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 55.60it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47, train loss: 0.180, valid rmspe: 0.219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.11it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 54.92it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48, train loss: 0.178, valid rmspe: 0.229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 31.96it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 45.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49, train loss: 0.178, valid rmspe: 0.228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3 train: (343146, 100), valid: (85786, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.20it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 54.55it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss: 64.792, valid rmspe: 27.260\n",
      "new best:27.260080337524414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 31.87it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 52.49it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss: 16.855, valid rmspe: 17.200\n",
      "new best:17.199552536010742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.74it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.94it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, train loss: 10.589, valid rmspe: 16.529\n",
      "new best:16.52877426147461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 30.80it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.51it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, train loss: 10.201, valid rmspe: 15.822\n",
      "new best:15.821653366088867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 31.86it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 49.06it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, train loss: 7.245, valid rmspe: 7.917\n",
      "new best:7.916903018951416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.40it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.05it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, train loss: 6.813, valid rmspe: 3.954\n",
      "new best:3.953911066055298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.77it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 55.03it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, train loss: 4.914, valid rmspe: 3.415\n",
      "new best:3.415496587753296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 30.67it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.52it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, train loss: 3.395, valid rmspe: 1.772\n",
      "new best:1.7722396850585938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.22it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.31it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, train loss: 2.261, valid rmspe: 2.378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.08it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.07it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, train loss: 2.141, valid rmspe: 3.395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.77it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 46.30it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, train loss: 2.036, valid rmspe: 2.765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 31.34it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.10it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, train loss: 1.451, valid rmspe: 1.860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.20it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.25it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, train loss: 0.938, valid rmspe: 0.330\n",
      "new best:0.3299013674259186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.30it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.56it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, train loss: 0.670, valid rmspe: 0.494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 30.48it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 46.48it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, train loss: 0.571, valid rmspe: 0.462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.00it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 55.39it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, train loss: 0.576, valid rmspe: 0.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.10it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 55.96it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, train loss: 0.599, valid rmspe: 0.913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.92it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 52.25it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, train loss: 0.446, valid rmspe: 0.909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 30.30it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 54.88it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, train loss: 0.502, valid rmspe: 0.261\n",
      "new best:0.2610951066017151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.05it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.70it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, train loss: 0.399, valid rmspe: 0.307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.01it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.91it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, train loss: 0.443, valid rmspe: 0.333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.46it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.05it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21, train loss: 0.420, valid rmspe: 0.341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 30.61it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.45it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22, train loss: 0.307, valid rmspe: 0.307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.76it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.10it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23, train loss: 0.272, valid rmspe: 0.259\n",
      "new best:0.2590181529521942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 31.86it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.77it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24, train loss: 0.264, valid rmspe: 0.260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.66it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 45.57it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25, train loss: 0.253, valid rmspe: 0.237\n",
      "new best:0.23674140870571136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 31.33it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 55.81it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26, train loss: 0.243, valid rmspe: 0.234\n",
      "new best:0.23390717804431915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.84it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.35it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27, train loss: 0.238, valid rmspe: 0.220\n",
      "new best:0.22028037905693054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.24it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.87it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28, train loss: 0.221, valid rmspe: 0.213\n",
      "new best:0.213115856051445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.12it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 46.43it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29, train loss: 0.221, valid rmspe: 0.227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 31.73it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.45it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30, train loss: 0.217, valid rmspe: 0.218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.73it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.50it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31, train loss: 0.212, valid rmspe: 0.216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.63it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.77it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32, train loss: 0.213, valid rmspe: 0.210\n",
      "new best:0.21025611460208893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 31.78it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 46.86it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33, train loss: 0.212, valid rmspe: 0.211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 31.74it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.11it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34, train loss: 0.220, valid rmspe: 0.213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.77it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.83it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35, train loss: 0.215, valid rmspe: 0.283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.89it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.17it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36, train loss: 0.220, valid rmspe: 0.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 30.56it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 46.84it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37, train loss: 0.215, valid rmspe: 0.214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.89it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.27it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38, train loss: 0.217, valid rmspe: 0.212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.79it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 55.89it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39, train loss: 0.207, valid rmspe: 0.210\n",
      "new best:0.20985743403434753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.74it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 44.46it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40, train loss: 0.205, valid rmspe: 0.214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 30.50it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.20it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41, train loss: 0.206, valid rmspe: 0.207\n",
      "new best:0.20731814205646515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.00it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.47it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42, train loss: 0.206, valid rmspe: 0.210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.63it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.40it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43, train loss: 0.213, valid rmspe: 0.211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.31it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.65it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44, train loss: 0.206, valid rmspe: 0.209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 30.13it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 54.88it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45, train loss: 0.203, valid rmspe: 0.224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.54it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.25it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46, train loss: 0.205, valid rmspe: 0.299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.15it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.13it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47, train loss: 0.204, valid rmspe: 0.254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.87it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 48.51it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48, train loss: 0.210, valid rmspe: 0.224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 30.40it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.36it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49, train loss: 0.204, valid rmspe: 0.207\n",
      "fold 4 train: (343146, 100), valid: (85786, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.14it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.50it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss: 76.597, valid rmspe: 32.162\n",
      "new best:32.16170120239258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.73it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.41it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss: 17.373, valid rmspe: 32.259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.33it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 48.04it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, train loss: 14.836, valid rmspe: 56.040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 30.84it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 47.32it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, train loss: 10.675, valid rmspe: 12.686\n",
      "new best:12.686274528503418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.64it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.77it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, train loss: 7.536, valid rmspe: 12.382\n",
      "new best:12.38157844543457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.08it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 55.15it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, train loss: 5.255, valid rmspe: 4.018\n",
      "new best:4.017996311187744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.01it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 55.84it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, train loss: 5.158, valid rmspe: 2.717\n",
      "new best:2.7166810035705566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.41it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.08it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, train loss: 3.086, valid rmspe: 2.644\n",
      "new best:2.6435508728027344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.99it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.99it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, train loss: 2.478, valid rmspe: 3.307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.71it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 47.77it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, train loss: 1.575, valid rmspe: 2.423\n",
      "new best:2.423220634460449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 29.92it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.11it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, train loss: 1.507, valid rmspe: 0.644\n",
      "new best:0.6443920135498047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.20it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.29it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, train loss: 0.945, valid rmspe: 0.941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.89it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 55.86it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, train loss: 0.613, valid rmspe: 0.568\n",
      "new best:0.5677054524421692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.44it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.46it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, train loss: 0.446, valid rmspe: 0.350\n",
      "new best:0.3503914773464203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.05it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 55.32it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, train loss: 0.314, valid rmspe: 0.288\n",
      "new best:0.28811246156692505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.18it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.06it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, train loss: 0.275, valid rmspe: 0.264\n",
      "new best:0.263587087392807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.13it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.16it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, train loss: 0.238, valid rmspe: 0.225\n",
      "new best:0.22510026395320892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:09<00:00, 29.37it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.84it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, train loss: 0.235, valid rmspe: 0.220\n",
      "new best:0.21974220871925354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.64it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.01it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, train loss: 0.224, valid rmspe: 0.246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.97it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.83it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, train loss: 0.222, valid rmspe: 0.235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.61it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.02it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, train loss: 0.228, valid rmspe: 0.225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.03it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.34it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21, train loss: 0.222, valid rmspe: 0.224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.10it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.02it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22, train loss: 0.221, valid rmspe: 0.235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.20it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.10it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23, train loss: 0.213, valid rmspe: 0.222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 30.28it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 47.44it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24, train loss: 0.217, valid rmspe: 0.210\n",
      "new best:0.21006739139556885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.97it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.23it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25, train loss: 0.214, valid rmspe: 0.219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.12it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 49.68it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26, train loss: 0.213, valid rmspe: 0.212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.66it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 53.21it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27, train loss: 0.213, valid rmspe: 0.211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.14it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 55.42it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28, train loss: 0.211, valid rmspe: 0.223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.59it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.63it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29, train loss: 0.211, valid rmspe: 0.217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.48it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.53it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30, train loss: 0.208, valid rmspe: 0.215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 31.35it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 48.18it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31, train loss: 0.213, valid rmspe: 0.215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.26it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.01it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32, train loss: 0.207, valid rmspe: 0.215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 31.89it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.18it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33, train loss: 0.214, valid rmspe: 0.217\n",
      "Epoch    34: reducing learning rate of group 0 to 1.1400e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.75it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.73it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34, train loss: 0.197, valid rmspe: 0.223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.00it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.82it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35, train loss: 0.195, valid rmspe: 0.206\n",
      "new best:0.20552855730056763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.75it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 46.39it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36, train loss: 0.193, valid rmspe: 0.211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.85it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 55.65it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37, train loss: 0.191, valid rmspe: 0.208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 31.73it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 47.71it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38, train loss: 0.193, valid rmspe: 0.206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 31.32it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.02it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39, train loss: 0.188, valid rmspe: 0.217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.47it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.89it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40, train loss: 0.187, valid rmspe: 0.206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.59it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.07it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41, train loss: 0.188, valid rmspe: 0.208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.91it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.69it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42, train loss: 0.184, valid rmspe: 0.207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.18it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.19it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43, train loss: 0.184, valid rmspe: 0.211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.19it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.92it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44, train loss: 0.183, valid rmspe: 0.208\n",
      "Epoch    45: reducing learning rate of group 0 to 3.4200e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.99it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 47.18it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45, train loss: 0.178, valid rmspe: 0.206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 29.96it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 55.53it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46, train loss: 0.176, valid rmspe: 0.208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.03it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.21it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47, train loss: 0.176, valid rmspe: 0.212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.16it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.19it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48, train loss: 0.175, valid rmspe: 0.213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.88it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 53.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49, train loss: 0.174, valid rmspe: 0.212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 train: (343145, 100), valid: (85787, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.50it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 55.80it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss: 66.252, valid rmspe: 26.419\n",
      "new best:26.41870880126953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.46it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 47.24it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss: 21.299, valid rmspe: 23.458\n",
      "new best:23.457929611206055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:09<00:00, 29.41it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.40it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, train loss: 14.772, valid rmspe: 7.716\n",
      "new best:7.715919017791748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.66it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.73it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, train loss: 10.488, valid rmspe: 15.074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.61it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 55.51it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, train loss: 7.833, valid rmspe: 5.015\n",
      "new best:5.015052795410156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.70it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 55.10it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, train loss: 5.954, valid rmspe: 15.907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.73it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.08it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, train loss: 5.969, valid rmspe: 3.811\n",
      "new best:3.8111298084259033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.90it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.47it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, train loss: 3.099, valid rmspe: 5.494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.21it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.35it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, train loss: 2.612, valid rmspe: 1.025\n",
      "new best:1.0251907110214233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 30.11it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 50.02it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, train loss: 1.607, valid rmspe: 1.349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.81it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.97it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, train loss: 1.170, valid rmspe: 0.681\n",
      "new best:0.6810293793678284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.86it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 48.95it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, train loss: 0.417, valid rmspe: 0.243\n",
      "new best:0.2433573454618454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.15it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.83it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, train loss: 0.279, valid rmspe: 0.234\n",
      "new best:0.2335636168718338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.18it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.01it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, train loss: 0.246, valid rmspe: 0.269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.04it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.69it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, train loss: 0.231, valid rmspe: 0.228\n",
      "new best:0.22786305844783783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.40it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.16it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, train loss: 0.232, valid rmspe: 0.219\n",
      "new best:0.2189715951681137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 30.86it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 47.73it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, train loss: 0.225, valid rmspe: 0.252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 31.69it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.53it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, train loss: 0.229, valid rmspe: 0.224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.67it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.94it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, train loss: 0.226, valid rmspe: 0.214\n",
      "new best:0.21353048086166382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.87it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.50it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, train loss: 0.220, valid rmspe: 0.231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.12it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.34it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, train loss: 0.221, valid rmspe: 0.228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.50it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.59it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21, train loss: 0.217, valid rmspe: 0.254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.71it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.44it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22, train loss: 0.222, valid rmspe: 0.218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.25it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 45.90it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23, train loss: 0.222, valid rmspe: 0.230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 30.67it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 53.68it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24, train loss: 0.223, valid rmspe: 0.228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.76it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.01it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25, train loss: 0.213, valid rmspe: 0.256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.34it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.72it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26, train loss: 0.215, valid rmspe: 0.246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.68it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 55.06it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27, train loss: 0.214, valid rmspe: 0.218\n",
      "Epoch    28: reducing learning rate of group 0 to 1.1400e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.67it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.31it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28, train loss: 0.202, valid rmspe: 0.227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.07it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.64it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29, train loss: 0.200, valid rmspe: 0.215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.72it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.89it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30, train loss: 0.200, valid rmspe: 0.211\n",
      "new best:0.21093600988388062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:09<00:00, 28.99it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 47.51it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31, train loss: 0.199, valid rmspe: 0.214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.87it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.06it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32, train loss: 0.197, valid rmspe: 0.212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.14it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.59it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33, train loss: 0.198, valid rmspe: 0.210\n",
      "new best:0.21028441190719604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.86it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 46.27it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34, train loss: 0.196, valid rmspe: 0.219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.89it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.59it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35, train loss: 0.196, valid rmspe: 0.220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.77it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.23it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36, train loss: 0.197, valid rmspe: 0.212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.12it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.34it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37, train loss: 0.194, valid rmspe: 0.210\n",
      "new best:0.2100549340248108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 30.81it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 47.73it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38, train loss: 0.192, valid rmspe: 0.214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 31.68it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.24it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39, train loss: 0.193, valid rmspe: 0.210\n",
      "new best:0.20951223373413086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.92it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.11it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40, train loss: 0.194, valid rmspe: 0.211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.26it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.18it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41, train loss: 0.189, valid rmspe: 0.215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.50it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.66it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42, train loss: 0.198, valid rmspe: 0.220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.59it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.13it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43, train loss: 0.190, valid rmspe: 0.218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.62it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 52.35it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44, train loss: 0.188, valid rmspe: 0.209\n",
      "new best:0.2087356597185135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.79it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 47.50it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45, train loss: 0.187, valid rmspe: 0.218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 30.40it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.67it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46, train loss: 0.185, valid rmspe: 0.211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.93it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.15it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47, train loss: 0.185, valid rmspe: 0.221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.58it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 55.77it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48, train loss: 0.186, valid rmspe: 0.213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.96it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 54.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49, train loss: 0.183, valid rmspe: 0.208\n",
      "new best:0.20849047601222992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 train: (343145, 100), valid: (85787, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.11it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 54.61it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss: 64.377, valid rmspe: 31.051\n",
      "new best:31.050561904907227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.32it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 55.85it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss: 18.773, valid rmspe: 12.182\n",
      "new best:12.181533813476562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.00it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.12it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, train loss: 13.553, valid rmspe: 7.844\n",
      "new best:7.843871116638184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 30.13it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 45.27it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, train loss: 10.506, valid rmspe: 5.735\n",
      "new best:5.735016822814941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 31.71it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.88it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, train loss: 8.651, valid rmspe: 14.365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.33it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.43it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, train loss: 6.727, valid rmspe: 3.092\n",
      "new best:3.09211802482605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.94it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.89it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, train loss: 4.585, valid rmspe: 2.173\n",
      "new best:2.1726107597351074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.08it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 45.13it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, train loss: 3.266, valid rmspe: 1.374\n",
      "new best:1.3743587732315063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.81it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.55it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, train loss: 3.018, valid rmspe: 6.445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.12it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.56it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, train loss: 2.071, valid rmspe: 1.513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.29it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 47.32it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, train loss: 1.863, valid rmspe: 1.598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:09<00:00, 29.39it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.06it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, train loss: 1.275, valid rmspe: 0.501\n",
      "new best:0.5008829236030579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.23it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.20it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, train loss: 0.753, valid rmspe: 1.272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.21it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.28it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, train loss: 0.843, valid rmspe: 0.754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.61it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.06it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, train loss: 0.660, valid rmspe: 0.445\n",
      "new best:0.44472241401672363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.22it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 54.94it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, train loss: 0.454, valid rmspe: 0.331\n",
      "new best:0.33125317096710205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.04it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.56it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, train loss: 0.422, valid rmspe: 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.28it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 53.39it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, train loss: 0.363, valid rmspe: 0.234\n",
      "new best:0.23389244079589844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 30.71it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 46.15it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, train loss: 0.310, valid rmspe: 0.657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.22it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 55.64it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, train loss: 0.310, valid rmspe: 0.303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.44it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.77it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, train loss: 0.284, valid rmspe: 0.237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.61it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.18it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21, train loss: 0.250, valid rmspe: 0.277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.67it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.34it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22, train loss: 0.243, valid rmspe: 0.225\n",
      "new best:0.22546446323394775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.13it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.78it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23, train loss: 0.240, valid rmspe: 0.234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.50it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 55.01it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24, train loss: 0.228, valid rmspe: 0.213\n",
      "new best:0.21277911961078644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 31.33it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 43.82it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25, train loss: 0.222, valid rmspe: 0.224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 30.19it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 55.53it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26, train loss: 0.219, valid rmspe: 0.241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.24it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 55.91it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27, train loss: 0.220, valid rmspe: 0.217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.96it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.01it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28, train loss: 0.217, valid rmspe: 0.216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.51it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.05it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29, train loss: 0.217, valid rmspe: 0.212\n",
      "new best:0.21225956082344055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.04it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 45.18it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30, train loss: 0.218, valid rmspe: 0.213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.68it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.96it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31, train loss: 0.220, valid rmspe: 0.208\n",
      "new best:0.20774374902248383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.53it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.22it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32, train loss: 0.219, valid rmspe: 0.214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 30.14it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 47.44it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33, train loss: 0.217, valid rmspe: 0.207\n",
      "new best:0.20741283893585205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 30.90it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.07it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34, train loss: 0.223, valid rmspe: 0.214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.18it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.50it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35, train loss: 0.212, valid rmspe: 0.215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.92it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 55.94it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36, train loss: 0.210, valid rmspe: 0.208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.46it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.26it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37, train loss: 0.213, valid rmspe: 0.219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.03it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.27it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38, train loss: 0.218, valid rmspe: 0.251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.97it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.22it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39, train loss: 0.218, valid rmspe: 0.207\n",
      "new best:0.20733126997947693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 31.86it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 43.06it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40, train loss: 0.212, valid rmspe: 0.208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:09<00:00, 29.77it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.62it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41, train loss: 0.211, valid rmspe: 0.210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.08it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.80it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42, train loss: 0.209, valid rmspe: 0.221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.89it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.91it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43, train loss: 0.207, valid rmspe: 0.234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.29it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 55.67it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44, train loss: 0.209, valid rmspe: 0.211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.09it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.96it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45, train loss: 0.209, valid rmspe: 0.261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.98it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.68it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46, train loss: 0.216, valid rmspe: 0.205\n",
      "new best:0.20523984730243683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.46it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.54it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47, train loss: 0.212, valid rmspe: 0.279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 30.58it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 47.01it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48, train loss: 0.231, valid rmspe: 0.209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 31.07it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49, train loss: 0.211, valid rmspe: 0.244\n",
      "fold 2 train: (343146, 100), valid: (85786, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.18it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.75it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss: 63.716, valid rmspe: 30.100\n",
      "new best:30.10003089904785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.15it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 55.92it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss: 15.911, valid rmspe: 13.828\n",
      "new best:13.828407287597656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.13it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.31it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, train loss: 10.272, valid rmspe: 14.434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.45it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 47.92it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, train loss: 9.739, valid rmspe: 16.139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.44it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.78it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, train loss: 8.780, valid rmspe: 11.686\n",
      "new best:11.686483383178711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.85it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 46.82it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, train loss: 5.932, valid rmspe: 5.578\n",
      "new best:5.577866554260254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 29.94it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 47.46it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, train loss: 4.159, valid rmspe: 2.952\n",
      "new best:2.9520106315612793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 31.81it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 55.47it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, train loss: 3.124, valid rmspe: 4.906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.08it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 59.26it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, train loss: 2.229, valid rmspe: 2.363\n",
      "new best:2.363154172897339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.13it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.18it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, train loss: 1.952, valid rmspe: 3.258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.00it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.87it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, train loss: 1.033, valid rmspe: 1.725\n",
      "new best:1.7248499393463135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.94it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.28it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, train loss: 0.491, valid rmspe: 0.318\n",
      "new best:0.3178824782371521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.43it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.51it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, train loss: 0.262, valid rmspe: 0.320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 31.12it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 47.43it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, train loss: 0.241, valid rmspe: 0.236\n",
      "new best:0.23596689105033875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 30.40it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.92it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, train loss: 0.237, valid rmspe: 0.255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.99it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.08it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, train loss: 0.230, valid rmspe: 0.232\n",
      "new best:0.23228763043880463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.64it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 47.67it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, train loss: 0.227, valid rmspe: 0.232\n",
      "new best:0.23185686767101288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.96it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.60it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, train loss: 0.221, valid rmspe: 0.226\n",
      "new best:0.22587990760803223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.09it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.93it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, train loss: 0.219, valid rmspe: 0.225\n",
      "new best:0.22454389929771423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.03it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.04it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, train loss: 0.219, valid rmspe: 0.242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.69it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.62it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, train loss: 0.217, valid rmspe: 0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 30.52it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 48.06it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21, train loss: 0.217, valid rmspe: 0.233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 31.27it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.73it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22, train loss: 0.215, valid rmspe: 0.234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.02it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.80it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23, train loss: 0.216, valid rmspe: 0.226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.68it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.86it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24, train loss: 0.210, valid rmspe: 0.224\n",
      "new best:0.22448812425136566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.95it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.25it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25, train loss: 0.213, valid rmspe: 0.225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.48it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 48.67it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26, train loss: 0.218, valid rmspe: 0.229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.36it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.53it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27, train loss: 0.219, valid rmspe: 0.228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.94it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 47.99it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28, train loss: 0.224, valid rmspe: 0.275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:09<00:00, 29.70it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 44.85it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29, train loss: 0.218, valid rmspe: 0.231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 31.65it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.11it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30, train loss: 0.222, valid rmspe: 0.219\n",
      "new best:0.21948190033435822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.29it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.94it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31, train loss: 0.217, valid rmspe: 0.222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.99it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.17it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32, train loss: 0.211, valid rmspe: 0.227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.52it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.29it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33, train loss: 0.207, valid rmspe: 0.230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.98it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.85it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34, train loss: 0.212, valid rmspe: 0.237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.58it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.72it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35, train loss: 0.206, valid rmspe: 0.212\n",
      "new best:0.21210666000843048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 31.08it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 46.09it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36, train loss: 0.205, valid rmspe: 0.219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 30.42it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 48.50it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37, train loss: 0.206, valid rmspe: 0.243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.79it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.73it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38, train loss: 0.214, valid rmspe: 0.230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.95it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 44.65it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39, train loss: 0.205, valid rmspe: 0.213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.74it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.83it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40, train loss: 0.201, valid rmspe: 0.209\n",
      "new best:0.2090134620666504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.07it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.42it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41, train loss: 0.204, valid rmspe: 0.248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.23it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.85it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42, train loss: 0.204, valid rmspe: 0.217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.78it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.78it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43, train loss: 0.203, valid rmspe: 0.210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 31.11it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 45.55it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44, train loss: 0.200, valid rmspe: 0.222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:09<00:00, 29.51it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.22it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45, train loss: 0.199, valid rmspe: 0.207\n",
      "new best:0.20748409628868103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.37it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.11it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46, train loss: 0.198, valid rmspe: 0.221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.93it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.65it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47, train loss: 0.204, valid rmspe: 0.219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.92it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.10it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48, train loss: 0.201, valid rmspe: 0.211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.26it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.27it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49, train loss: 0.200, valid rmspe: 0.217\n",
      "fold 3 train: (343146, 100), valid: (85786, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.73it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.35it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss: 71.106, valid rmspe: 44.150\n",
      "new best:44.14954376220703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.05it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 55.89it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss: 19.912, valid rmspe: 44.908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.18it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 54.91it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, train loss: 14.387, valid rmspe: 32.660\n",
      "new best:32.65995407104492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.10it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.38it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, train loss: 10.296, valid rmspe: 6.847\n",
      "new best:6.846987724304199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.23it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.69it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, train loss: 6.781, valid rmspe: 12.481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.81it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.87it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, train loss: 6.594, valid rmspe: 3.943\n",
      "new best:3.9434001445770264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.32it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.04it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, train loss: 4.245, valid rmspe: 5.223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.86it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.01it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, train loss: 3.839, valid rmspe: 2.869\n",
      "new best:2.8685333728790283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 31.28it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 48.31it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, train loss: 3.480, valid rmspe: 3.587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:09<00:00, 29.25it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 49.26it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, train loss: 2.124, valid rmspe: 0.913\n",
      "new best:0.913148045539856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.57it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.71it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, train loss: 1.768, valid rmspe: 1.351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.64it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.35it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, train loss: 1.217, valid rmspe: 1.306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.04it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 44.66it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, train loss: 0.947, valid rmspe: 1.422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.04it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.99it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, train loss: 0.923, valid rmspe: 0.958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.88it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.29it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, train loss: 0.721, valid rmspe: 0.612\n",
      "new best:0.6116026639938354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.60it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.81it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, train loss: 0.590, valid rmspe: 0.406\n",
      "new best:0.40617501735687256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.32it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 54.76it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, train loss: 0.575, valid rmspe: 0.421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.68it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.19it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, train loss: 0.473, valid rmspe: 0.299\n",
      "new best:0.2994498312473297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.09it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.42it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, train loss: 0.465, valid rmspe: 0.310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 31.86it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.46it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, train loss: 0.343, valid rmspe: 0.370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.93it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.56it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, train loss: 0.339, valid rmspe: 0.256\n",
      "new best:0.2558667063713074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.94it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.36it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21, train loss: 0.306, valid rmspe: 0.242\n",
      "new best:0.24223242700099945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 31.83it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 39.18it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22, train loss: 0.338, valid rmspe: 0.370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:09<00:00, 29.55it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 47.41it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23, train loss: 0.310, valid rmspe: 0.300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.58it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 55.87it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24, train loss: 0.273, valid rmspe: 0.249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.48it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 55.09it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25, train loss: 0.246, valid rmspe: 0.246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.53it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.00it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26, train loss: 0.244, valid rmspe: 0.226\n",
      "new best:0.22569625079631805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.92it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 54.77it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27, train loss: 0.239, valid rmspe: 0.217\n",
      "new best:0.21726709604263306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.74it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 54.51it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28, train loss: 0.226, valid rmspe: 0.211\n",
      "new best:0.21139837801456451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.62it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.94it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29, train loss: 0.222, valid rmspe: 0.226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.76it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.70it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30, train loss: 0.222, valid rmspe: 0.210\n",
      "new best:0.20975925028324127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.05it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.73it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31, train loss: 0.215, valid rmspe: 0.234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.48it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.83it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32, train loss: 0.215, valid rmspe: 0.209\n",
      "new best:0.2093946486711502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.94it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.57it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33, train loss: 0.216, valid rmspe: 0.230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.79it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.28it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34, train loss: 0.219, valid rmspe: 0.227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.06it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 55.53it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35, train loss: 0.217, valid rmspe: 0.229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.50it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 47.35it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36, train loss: 0.218, valid rmspe: 0.216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 30.20it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 47.36it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37, train loss: 0.222, valid rmspe: 0.209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 31.93it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.26it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38, train loss: 0.220, valid rmspe: 0.219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.44it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.22it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39, train loss: 0.221, valid rmspe: 0.209\n",
      "new best:0.2091585248708725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.10it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.11it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40, train loss: 0.217, valid rmspe: 0.220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.17it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.08it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41, train loss: 0.229, valid rmspe: 0.218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.35it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.81it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42, train loss: 0.221, valid rmspe: 0.229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.17it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.46it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43, train loss: 0.216, valid rmspe: 0.219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.23it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.11it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44, train loss: 0.219, valid rmspe: 0.228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.01it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 43.51it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45, train loss: 0.227, valid rmspe: 0.215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.01it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.48it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46, train loss: 0.218, valid rmspe: 0.248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.15it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.23it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47, train loss: 0.218, valid rmspe: 0.207\n",
      "new best:0.20739293098449707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.03it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.96it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48, train loss: 0.211, valid rmspe: 0.207\n",
      "new best:0.20736925303936005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.45it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.99it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49, train loss: 0.213, valid rmspe: 0.247\n",
      "fold 4 train: (343146, 100), valid: (85786, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.05it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 54.16it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss: 64.995, valid rmspe: 140.336\n",
      "new best:140.33609008789062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 30.28it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 47.73it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss: 20.926, valid rmspe: 25.520\n",
      "new best:25.520301818847656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:09<00:00, 29.65it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.61it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, train loss: 12.025, valid rmspe: 12.186\n",
      "new best:12.186317443847656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.99it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.99it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, train loss: 9.850, valid rmspe: 105.198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.44it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 55.61it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, train loss: 6.733, valid rmspe: 4.640\n",
      "new best:4.640467166900635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.55it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 59.08it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, train loss: 5.766, valid rmspe: 4.722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.44it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.49it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, train loss: 4.819, valid rmspe: 8.671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.78it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.90it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, train loss: 3.279, valid rmspe: 18.057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.66it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.04it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, train loss: 3.360, valid rmspe: 3.607\n",
      "new best:3.6070730686187744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.56it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.21it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, train loss: 2.270, valid rmspe: 3.131\n",
      "new best:3.1312036514282227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.27it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.50it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, train loss: 1.524, valid rmspe: 5.095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.09it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.82it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, train loss: 1.519, valid rmspe: 1.885\n",
      "new best:1.8846184015274048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.64it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.93it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, train loss: 1.211, valid rmspe: 1.033\n",
      "new best:1.0327377319335938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.92it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.67it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, train loss: 0.916, valid rmspe: 1.558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:07<00:00, 33.65it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.02it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, train loss: 0.773, valid rmspe: 0.827\n",
      "new best:0.8271812200546265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 31.19it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 46.75it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, train loss: 0.876, valid rmspe: 1.980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 30.51it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 48.10it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, train loss: 0.659, valid rmspe: 0.529\n",
      "new best:0.5286280512809753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.08it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.60it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, train loss: 0.573, valid rmspe: 0.277\n",
      "new best:0.27674928307533264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.00it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 49.21it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, train loss: 0.453, valid rmspe: 0.407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.82it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 54.37it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, train loss: 0.488, valid rmspe: 0.491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.48it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.41it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, train loss: 0.443, valid rmspe: 0.308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.94it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.39it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21, train loss: 0.379, valid rmspe: 0.252\n",
      "new best:0.25160375237464905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.71it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.73it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22, train loss: 0.454, valid rmspe: 0.367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.08it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.93it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23, train loss: 0.298, valid rmspe: 0.262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.75it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.81it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24, train loss: 0.322, valid rmspe: 0.252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.81it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.17it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25, train loss: 0.379, valid rmspe: 0.269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.80it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.65it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26, train loss: 0.393, valid rmspe: 0.452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.33it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.10it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27, train loss: 0.284, valid rmspe: 0.244\n",
      "new best:0.24361968040466309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.15it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.00it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28, train loss: 0.273, valid rmspe: 0.216\n",
      "new best:0.21649813652038574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.58it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 59.17it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29, train loss: 0.250, valid rmspe: 0.252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 30.19it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 47.24it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30, train loss: 0.239, valid rmspe: 0.230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 30.54it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.85it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31, train loss: 0.235, valid rmspe: 0.237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.50it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.17it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32, train loss: 0.229, valid rmspe: 0.234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.19it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.24it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33, train loss: 0.225, valid rmspe: 0.343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.88it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 55.60it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34, train loss: 0.218, valid rmspe: 0.249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.51it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.85it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35, train loss: 0.214, valid rmspe: 0.218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.99it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.47it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36, train loss: 0.213, valid rmspe: 0.217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.86it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.10it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37, train loss: 0.213, valid rmspe: 0.212\n",
      "new best:0.21174734830856323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.17it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 43.79it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38, train loss: 0.213, valid rmspe: 0.210\n",
      "new best:0.20987187325954437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.89it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.41it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39, train loss: 0.209, valid rmspe: 0.212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.40it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.26it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40, train loss: 0.207, valid rmspe: 0.225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 33.14it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.30it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41, train loss: 0.206, valid rmspe: 0.295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.66it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.41it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42, train loss: 0.211, valid rmspe: 0.211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.52it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.57it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43, train loss: 0.208, valid rmspe: 0.236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.09it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 46.23it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44, train loss: 0.206, valid rmspe: 0.223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:09<00:00, 29.38it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 47.87it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45, train loss: 0.206, valid rmspe: 0.216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 31.97it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 57.78it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46, train loss: 0.205, valid rmspe: 0.217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.92it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 58.00it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47, train loss: 0.199, valid rmspe: 0.209\n",
      "new best:0.20877887308597565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.40it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.71it/s]\n",
      "Training:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48, train loss: 0.207, valid rmspe: 0.221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 269/269 [00:08<00:00, 32.99it/s]\n",
      "Evaluating: 100%|██████████| 68/68 [00:01<00:00, 56.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49, train loss: 0.199, valid rmspe: 0.217\n",
      "number of models are less than top_n. all models will be used\n",
      "total 0 models will be used.\n",
      "train full\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 148.93938| val_0_rmspe: 182.3109130859375|  0:00:06s\n",
      "epoch 10 | loss: 0.37464 | val_0_rmspe: 0.3318299949169159|  0:01:06s\n",
      "epoch 20 | loss: 0.31154 | val_0_rmspe: 0.2739799916744232|  0:02:07s\n",
      "epoch 30 | loss: 0.26879 | val_0_rmspe: 0.3022800087928772|  0:03:10s\n",
      "epoch 40 | loss: 0.25805 | val_0_rmspe: 0.256879985332489|  0:04:11s\n",
      "epoch 50 | loss: 0.22806 | val_0_rmspe: 0.24426999688148499|  0:05:12s\n",
      "epoch 60 | loss: 0.27576 | val_0_rmspe: 0.2447900027036667|  0:06:15s\n",
      "epoch 70 | loss: 0.24968 | val_0_rmspe: 0.3140000104904175|  0:07:16s\n",
      "epoch 80 | loss: 0.23517 | val_0_rmspe: 0.2310200035572052|  0:08:17s\n",
      "epoch 90 | loss: 0.21914 | val_0_rmspe: 0.21807000041007996|  0:09:20s\n",
      "epoch 100| loss: 0.21627 | val_0_rmspe: 0.21592000126838684|  0:10:21s\n",
      "epoch 110| loss: 0.21365 | val_0_rmspe: 0.21478000283241272|  0:11:22s\n",
      "epoch 120| loss: 0.21627 | val_0_rmspe: 0.21517999470233917|  0:12:26s\n",
      "epoch 130| loss: 0.212   | val_0_rmspe: 0.2131499946117401|  0:13:28s\n",
      "epoch 140| loss: 0.21107 | val_0_rmspe: 0.2131900042295456|  0:14:29s\n",
      "epoch 150| loss: 0.20988 | val_0_rmspe: 0.21121999621391296|  0:15:33s\n",
      "epoch 160| loss: 0.20909 | val_0_rmspe: 0.21006999909877777|  0:16:34s\n",
      "epoch 170| loss: 0.20858 | val_0_rmspe: 0.2096800059080124|  0:17:36s\n",
      "epoch 180| loss: 0.2082  | val_0_rmspe: 0.20970000326633453|  0:18:40s\n",
      "epoch 190| loss: 0.20824 | val_0_rmspe: 0.209539994597435|  0:19:41s\n",
      "epoch 200| loss: 0.21689 | val_0_rmspe: 0.21735000610351562|  0:20:42s\n",
      "epoch 210| loss: 0.2794  | val_0_rmspe: 0.29025998711586|  0:21:48s\n",
      "epoch 220| loss: 0.26171 | val_0_rmspe: 0.24924999475479126|  0:22:50s\n",
      "epoch 230| loss: 0.23086 | val_0_rmspe: 0.23246000707149506|  0:23:51s\n",
      "epoch 240| loss: 0.22418 | val_0_rmspe: 0.22130000591278076|  0:24:55s\n",
      "\n",
      "Early stopping occured at epoch 241 with best_epoch = 191 and best_val_0_rmspe = 0.2093300074338913\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at artifacts/fold_0.pth.zip\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 139.62633| val_0_rmspe: 25.75242042541504|  0:00:06s\n",
      "epoch 10 | loss: 0.48975 | val_0_rmspe: 0.661899983882904|  0:01:06s\n",
      "epoch 20 | loss: 0.27993 | val_0_rmspe: 0.26469001173973083|  0:02:09s\n",
      "epoch 30 | loss: 0.27961 | val_0_rmspe: 0.2571699917316437|  0:03:09s\n",
      "epoch 40 | loss: 0.23643 | val_0_rmspe: 0.23543000221252441|  0:04:11s\n",
      "epoch 50 | loss: 0.22072 | val_0_rmspe: 0.22450999915599823|  0:05:14s\n",
      "epoch 60 | loss: 0.21428 | val_0_rmspe: 0.21702000498771667|  0:06:16s\n",
      "epoch 70 | loss: 0.21041 | val_0_rmspe: 0.21578000485897064|  0:07:16s\n",
      "epoch 80 | loss: 0.2099  | val_0_rmspe: 0.21698999404907227|  0:08:19s\n",
      "epoch 90 | loss: 0.20984 | val_0_rmspe: 0.21860000491142273|  0:09:20s\n",
      "epoch 100| loss: 0.2066  | val_0_rmspe: 0.2145400047302246|  0:10:21s\n",
      "epoch 110| loss: 0.20624 | val_0_rmspe: 0.2147900015115738|  0:11:25s\n",
      "epoch 120| loss: 0.20437 | val_0_rmspe: 0.2147199958562851|  0:12:26s\n",
      "epoch 130| loss: 0.20353 | val_0_rmspe: 0.21593999862670898|  0:13:27s\n",
      "epoch 140| loss: 0.20241 | val_0_rmspe: 0.21789999306201935|  0:14:31s\n",
      "\n",
      "Early stopping occured at epoch 147 with best_epoch = 97 and best_val_0_rmspe = 0.21258999407291412\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at artifacts/fold_1.pth.zip\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 148.40456| val_0_rmspe: 35.713111877441406|  0:00:06s\n",
      "epoch 10 | loss: 0.92911 | val_0_rmspe: 1.1637599468231201|  0:01:09s\n",
      "epoch 20 | loss: 0.80885 | val_0_rmspe: 0.47822999954223633|  0:02:14s\n",
      "epoch 30 | loss: 0.2538  | val_0_rmspe: 0.23902000486850739|  0:03:17s\n",
      "epoch 40 | loss: 0.23653 | val_0_rmspe: 0.23914000391960144|  0:04:19s\n",
      "epoch 50 | loss: 0.23733 | val_0_rmspe: 0.22982999682426453|  0:05:25s\n",
      "epoch 60 | loss: 0.22498 | val_0_rmspe: 0.22164000570774078|  0:06:27s\n",
      "epoch 70 | loss: 0.21725 | val_0_rmspe: 0.21493999660015106|  0:07:30s\n",
      "epoch 80 | loss: 0.21395 | val_0_rmspe: 0.21544000506401062|  0:08:35s\n",
      "epoch 90 | loss: 0.21688 | val_0_rmspe: 0.21594999730587006|  0:09:38s\n",
      "epoch 100| loss: 0.2135  | val_0_rmspe: 0.21469999849796295|  0:10:37s\n",
      "epoch 110| loss: 0.21102 | val_0_rmspe: 0.21161000430583954|  0:11:40s\n",
      "epoch 120| loss: 0.21061 | val_0_rmspe: 0.21469999849796295|  0:12:40s\n",
      "epoch 130| loss: 0.20919 | val_0_rmspe: 0.21069000661373138|  0:13:40s\n",
      "epoch 140| loss: 0.20759 | val_0_rmspe: 0.2096399962902069|  0:14:43s\n",
      "epoch 150| loss: 0.20696 | val_0_rmspe: 0.2094999998807907|  0:15:44s\n",
      "epoch 160| loss: 0.20791 | val_0_rmspe: 0.21104000508785248|  0:16:45s\n",
      "epoch 170| loss: 0.20605 | val_0_rmspe: 0.21008999645709991|  0:17:47s\n",
      "epoch 180| loss: 0.20557 | val_0_rmspe: 0.2100200057029724|  0:18:47s\n",
      "epoch 190| loss: 0.20544 | val_0_rmspe: 0.20935000479221344|  0:19:48s\n",
      "epoch 200| loss: 0.2788  | val_0_rmspe: 0.5748100280761719|  0:20:51s\n",
      "\n",
      "Early stopping occured at epoch 204 with best_epoch = 154 and best_val_0_rmspe = 0.20916999876499176\n",
      "Best weights from best epoch are automatically used!\n",
      "Successfully saved model at artifacts/fold_2.pth.zip\n",
      "number of models are less than top_n. all models will be used\n",
      "total 0 models will be used.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "def get_X(df_src):\n",
    "    cols = [c for c in df_src.columns if c not in ['time_id', 'target', 'tick_size', 'row_id']]\n",
    "    return df_src[cols]\n",
    "\n",
    "X = get_X(train)\n",
    "y = train['target']\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "def get_top_n_models(models, scores, top_n):\n",
    "    if len(models) <= top_n:\n",
    "        print('number of models are less than top_n. all models will be used')\n",
    "        return models\n",
    "    sorted_ = [(y, x) for y, x in sorted(zip(scores, models), key=lambda pair: pair[0])]\n",
    "    print(f'scores(sorted): {[y for y, _ in sorted_]}')\n",
    "    return [x for _, x in sorted_][:top_n]\n",
    "\n",
    "\n",
    "if False:\n",
    "    model_paths = []\n",
    "    scores = []\n",
    "    \n",
    "    if True:#if SHORTCUT_NN_IN_1ST_STAGE and IS_1ST_STAGE:\n",
    "        print('shortcut to save quota...')\n",
    "        epochs = 3\n",
    "        valid_th = 100\n",
    "    else:\n",
    "        epochs = 30\n",
    "        valid_th = NN_VALID_TH\n",
    "    \n",
    "    for i in range(3):\n",
    "        # MLP\n",
    "        nn_losses, nn_preds, scaler = train_nn(X, y, \n",
    "                                               # [folds[-1]], \n",
    "                                               device=device, \n",
    "                                               batch_size=512,\n",
    "                                               mlp_bn=True,\n",
    "                                               mlp_hidden=256,\n",
    "                                               mlp_dropout=0.0,\n",
    "                                               emb_dim=30,\n",
    "                                               epochs=epochs,\n",
    "                                               lr=0.002,\n",
    "                                               max_lr=0.0055,\n",
    "                                               weight_decay=1e-7,\n",
    "                                               model_path='mlp_fold_{}' + f\"_seed{i}.pth\",\n",
    "                                               seed=i)\n",
    "        if nn_losses[0] < NN_VALID_TH:\n",
    "            print(f'model of seed {i} added.')\n",
    "            scores.append(nn_losses[0])\n",
    "            model_paths.append(f'artifacts/mlp_fold_0_seed{i}.pth')\n",
    "            np.save(f'pred_mlp_seed{i}.npy', nn_preds[0])\n",
    "\n",
    "    model_paths = get_top_n_models(model_paths, scores, NN_MODEL_TOP_N)\n",
    "    mlp_model = [torch.load(path, device) for path in model_paths]\n",
    "    print(f'total {len(mlp_model)} models will be used.')\n",
    "    \n",
    "if True:\n",
    "    model_paths = []\n",
    "    scores = []\n",
    "        \n",
    "    if SHORTCUT_NN_IN_1ST_STAGE and IS_1ST_STAGE:\n",
    "        print('shortcut to save quota...')\n",
    "        epochs = 3\n",
    "        valid_th = 100\n",
    "    else:\n",
    "        epochs = 50\n",
    "        valid_th = NN_VALID_TH\n",
    "\n",
    "    for i in range(2):\n",
    "        nn_losses, nn_preds, scaler = train_nn(X, y, \n",
    "                                               #[folds[-1]], \n",
    "                                               device=device, \n",
    "                                               cnn_hidden=8*128,\n",
    "                                               batch_size=1280,\n",
    "                                               model_type='cnn',\n",
    "                                               emb_dim=30,\n",
    "                                               epochs=epochs, #epochs,\n",
    "                                               cnn_channel1=128,\n",
    "                                               cnn_channel2=3*128,\n",
    "                                               cnn_channel3=3*128,\n",
    "                                               lr=0.00038, #0.0011,\n",
    "                                               max_lr=0.0013,\n",
    "                                               weight_decay=6.5e-6,\n",
    "                                               optimizer_type='adam',\n",
    "                                               scheduler_type='reduce',\n",
    "                                               model_path='cnn_fold_{}' + f\"_seed{i}.pth\",\n",
    "                                               seed=i,\n",
    "                                               cnn_dropout=0.0,\n",
    "                                               cnn_weight_norm=True,\n",
    "                                               cnn_leaky_relu=False,\n",
    "                                               patience=8,\n",
    "                                               factor=0.3)\n",
    "        if nn_losses[0] < valid_th:\n",
    "            model_paths.append(f'artifacts/cnn_fold_0_seed{i}.pth')\n",
    "            scores.append(nn_losses[0])\n",
    "            np.save(f'pred_cnn_seed{i}.npy', nn_preds[0])\n",
    "            \n",
    "    model_paths = get_top_n_models(model_paths, scores, NN_MODEL_TOP_N)\n",
    "    cnn_model = [torch.load(path, device) for path in model_paths]\n",
    "    print(f'total {len(cnn_model)} models will be used.')\n",
    "\n",
    "    \n",
    "if True:\n",
    "    tab_model = []\n",
    "    scores = []\n",
    "        \n",
    "    if SHORTCUT_NN_IN_1ST_STAGE and IS_1ST_STAGE:\n",
    "        print('shortcut to save quota...')\n",
    "        epochs = 10\n",
    "        valid_th = 1000\n",
    "    else:\n",
    "        print('train full')\n",
    "        epochs = 250\n",
    "        valid_th = NN_VALID_TH\n",
    "\n",
    "    nn_losses, nn_preds, scaler, model = train_tabnet(X, y,  \n",
    "                                                      #[folds[-1]], \n",
    "                                                      batch_size=1280,\n",
    "                                                      epochs=epochs, #epochs,\n",
    "                                                      lr=0.04,\n",
    "                                                      patience=50,\n",
    "                                                      factor=0.5,\n",
    "                                                      gamma=1.6,\n",
    "                                                      lambda_sparse=3.55e-6,\n",
    "                                                      seed=2021,\n",
    "                                                      n_a=36)\n",
    "    if nn_losses[0] < valid_th:\n",
    "        tab_model.append(model)\n",
    "        scores.append(nn_losses[0])\n",
    "        np.save(f'pred_tab_seed.npy', nn_preds[0])\n",
    "        model.save_model(f'artifacts/tabnet_fold_0_seed')\n",
    "            \n",
    "    tab_model = get_top_n_models(tab_model, scores, TAB_MODEL_TOP_N)\n",
    "    print(f'total {len(tab_model)} models will be used.')\n",
    "    \n",
    "# about 1 hr\n",
    "# after pca to 100: about 45 min, weaker performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "024e8d2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T17:00:39.491278Z",
     "iopub.status.busy": "2023-12-13T17:00:39.490670Z",
     "iopub.status.idle": "2023-12-13T17:00:39.502000Z",
     "shell.execute_reply": "2023-12-13T17:00:39.501378Z",
     "shell.execute_reply.started": "2023-12-13T11:31:27.170960Z"
    },
    "papermill": {
     "duration": 13.510345,
     "end_time": "2023-12-13T17:00:39.502153",
     "exception": false,
     "start_time": "2023-12-13T17:00:25.991808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:427: RuntimeWarning: Mean of empty slice.\n",
      "/opt/conda/lib/python3.7/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "X_test = get_X(test)\n",
    "tab_preds = predict_tabnet(X_test, tab_model, scaler, ensemble_method=ENSEMBLE_METHOD).flatten()\n",
    "#cnn_preds = predict_nn(X_test, cnn_model, scaler, device, ensemble_method=ENSEMBLE_METHOD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747bfc49",
   "metadata": {
    "papermill": {
     "duration": 13.421369,
     "end_time": "2023-12-13T17:01:06.309585",
     "exception": false,
     "start_time": "2023-12-13T17:00:52.888216",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe4df4cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T17:01:33.190769Z",
     "iopub.status.busy": "2023-12-13T17:01:33.190107Z",
     "iopub.status.idle": "2023-12-13T17:24:29.347751Z",
     "shell.execute_reply": "2023-12-13T17:24:29.347114Z",
     "shell.execute_reply.started": "2023-12-13T11:31:37.189917Z"
    },
    "papermill": {
     "duration": 1389.621721,
     "end_time": "2023-12-13T17:24:29.347898",
     "exception": false,
     "start_time": "2023-12-13T17:01:19.726177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       ".datatable .frame thead tr.colnames {  background-image: url('data:image/png;base64,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');  background-repeat: repeat-x;  background-size: 14px;  height: 28px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's rmse: 0.000429005\ttraining's RMSPE: 0.198406\tvalid_1's rmse: 0.000441736\tvalid_1's RMSPE: 0.205029\n",
      "[500]\ttraining's rmse: 0.000406641\ttraining's RMSPE: 0.188063\tvalid_1's rmse: 0.000427725\tvalid_1's RMSPE: 0.198526\n",
      "[750]\ttraining's rmse: 0.000392987\ttraining's RMSPE: 0.181748\tvalid_1's rmse: 0.000420488\tvalid_1's RMSPE: 0.195167\n",
      "[1000]\ttraining's rmse: 0.000382851\ttraining's RMSPE: 0.177061\tvalid_1's rmse: 0.000416324\tvalid_1's RMSPE: 0.193234\n",
      "[1250]\ttraining's rmse: 0.000374682\ttraining's RMSPE: 0.173283\tvalid_1's rmse: 0.000413803\tvalid_1's RMSPE: 0.192064\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1300]\ttraining's rmse: 0.000373224\ttraining's RMSPE: 0.172609\tvalid_1's rmse: 0.000413174\tvalid_1's RMSPE: 0.191772\n",
      "Training fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's rmse: 0.000428514\ttraining's RMSPE: 0.198526\tvalid_1's rmse: 0.000440305\tvalid_1's RMSPE: 0.20294\n",
      "[500]\ttraining's rmse: 0.000406233\ttraining's RMSPE: 0.188203\tvalid_1's rmse: 0.000425532\tvalid_1's RMSPE: 0.196131\n",
      "[750]\ttraining's rmse: 0.000392085\ttraining's RMSPE: 0.181648\tvalid_1's rmse: 0.00041752\tvalid_1's RMSPE: 0.192438\n",
      "[1000]\ttraining's rmse: 0.000381894\ttraining's RMSPE: 0.176927\tvalid_1's rmse: 0.000412993\tvalid_1's RMSPE: 0.190351\n",
      "[1250]\ttraining's rmse: 0.000373694\ttraining's RMSPE: 0.173128\tvalid_1's rmse: 0.000410175\tvalid_1's RMSPE: 0.189053\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1300]\ttraining's rmse: 0.000372205\ttraining's RMSPE: 0.172438\tvalid_1's rmse: 0.000409671\tvalid_1's RMSPE: 0.18882\n",
      "Training fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's rmse: 0.000428116\ttraining's RMSPE: 0.197988\tvalid_1's rmse: 0.000469098\tvalid_1's RMSPE: 0.217759\n",
      "[500]\ttraining's rmse: 0.000406189\ttraining's RMSPE: 0.187847\tvalid_1's rmse: 0.000454434\tvalid_1's RMSPE: 0.210952\n",
      "[750]\ttraining's rmse: 0.000392273\ttraining's RMSPE: 0.181412\tvalid_1's rmse: 0.000447918\tvalid_1's RMSPE: 0.207927\n",
      "[1000]\ttraining's rmse: 0.000382141\ttraining's RMSPE: 0.176726\tvalid_1's rmse: 0.000443544\tvalid_1's RMSPE: 0.205896\n",
      "Early stopping, best iteration is:\n",
      "[1130]\ttraining's rmse: 0.000377742\ttraining's RMSPE: 0.174692\tvalid_1's rmse: 0.00044219\tvalid_1's RMSPE: 0.205268\n",
      "Training fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's rmse: 0.000427888\ttraining's RMSPE: 0.198236\tvalid_1's rmse: 0.000445434\tvalid_1's RMSPE: 0.205302\n",
      "[500]\ttraining's rmse: 0.000405576\ttraining's RMSPE: 0.187899\tvalid_1's rmse: 0.000430323\tvalid_1's RMSPE: 0.198337\n",
      "[750]\ttraining's rmse: 0.000392129\ttraining's RMSPE: 0.181669\tvalid_1's rmse: 0.000422881\tvalid_1's RMSPE: 0.194907\n",
      "[1000]\ttraining's rmse: 0.000381803\ttraining's RMSPE: 0.176885\tvalid_1's rmse: 0.000418265\tvalid_1's RMSPE: 0.19278\n",
      "[1250]\ttraining's rmse: 0.000373708\ttraining's RMSPE: 0.173135\tvalid_1's rmse: 0.00041568\tvalid_1's RMSPE: 0.191588\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1300]\ttraining's rmse: 0.000372255\ttraining's RMSPE: 0.172462\tvalid_1's rmse: 0.0004153\tvalid_1's RMSPE: 0.191413\n",
      "Training fold 5\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\ttraining's rmse: 0.000429063\ttraining's RMSPE: 0.19846\tvalid_1's rmse: 0.000443587\tvalid_1's RMSPE: 0.205775\n",
      "[500]\ttraining's rmse: 0.000407102\ttraining's RMSPE: 0.188302\tvalid_1's rmse: 0.00043016\tvalid_1's RMSPE: 0.199546\n",
      "[750]\ttraining's rmse: 0.000393288\ttraining's RMSPE: 0.181913\tvalid_1's rmse: 0.000422968\tvalid_1's RMSPE: 0.19621\n",
      "[1000]\ttraining's rmse: 0.00038307\ttraining's RMSPE: 0.177186\tvalid_1's rmse: 0.000418925\tvalid_1's RMSPE: 0.194334\n",
      "[1250]\ttraining's rmse: 0.000374749\ttraining's RMSPE: 0.173338\tvalid_1's rmse: 0.000415775\tvalid_1's RMSPE: 0.192873\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1300]\ttraining's rmse: 0.000373259\ttraining's RMSPE: 0.172648\tvalid_1's rmse: 0.00041566\tvalid_1's RMSPE: 0.19282\n",
      "Our out of folds RMSPE is 0.19410481639395613\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "\n",
    "seed0=2021\n",
    "params0 = {\n",
    "    'objective': 'rmse',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'max_depth': -1,\n",
    "    'max_bin':100,\n",
    "    'min_data_in_leaf':500,\n",
    "    'learning_rate': 0.05,\n",
    "    'subsample': 0.72,\n",
    "    'subsample_freq': 4,\n",
    "    'feature_fraction': 0.5,\n",
    "    'lambda_l1': 0.5,\n",
    "    'lambda_l2': 1.0,\n",
    "    'categorical_column':[0],\n",
    "    'seed':seed0,\n",
    "    'feature_fraction_seed': seed0,\n",
    "    'bagging_seed': seed0,\n",
    "    'drop_seed': seed0,\n",
    "    'data_random_seed': seed0,\n",
    "    'n_jobs':-1,\n",
    "    'verbose': -1}\n",
    "seed1=42\n",
    "params1 = {\n",
    "        'learning_rate': 0.1,        \n",
    "        'lambda_l1': 2,\n",
    "        'lambda_l2': 7,\n",
    "        'num_leaves': 800,\n",
    "        'min_sum_hessian_in_leaf': 20,\n",
    "        'feature_fraction': 0.8,\n",
    "        'feature_fraction_bynode': 0.8,\n",
    "        'bagging_fraction': 0.9,\n",
    "        'bagging_freq': 42,\n",
    "        'min_data_in_leaf': 700,\n",
    "        'max_depth': 4,\n",
    "        'categorical_column':[0],\n",
    "        'seed': seed1,\n",
    "        'feature_fraction_seed': seed1,\n",
    "        'bagging_seed': seed1,\n",
    "        'drop_seed': seed1,\n",
    "        'data_random_seed': seed1,\n",
    "        'objective': 'rmse',\n",
    "        'boosting': 'gbdt',\n",
    "        'verbosity': -1,\n",
    "        'n_jobs':-1,\n",
    "    }\n",
    "# Function to early stop with root mean squared percentage error\n",
    "def rmspe(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "\n",
    "def feval_rmspe(y_pred, lgb_train):\n",
    "    y_true = lgb_train.get_label()\n",
    "    return 'RMSPE', rmspe(y_true, y_pred), False\n",
    "\n",
    "def train_and_evaluate_lgb(train, test, params):\n",
    "    # Hyperparammeters (just basic)\n",
    "    \n",
    "    features = [col for col in train.columns if col not in {\"time_id\", \"target\", \"row_id\"}]\n",
    "    # Create out of folds array\n",
    "    y = train['target']\n",
    "    oof_predictions = np.zeros(train.shape[0])\n",
    "    # Create test array to store predictions\n",
    "    test_predictions = np.zeros(test.shape[0])\n",
    "    # Create a KFold object\n",
    "    kfold = KFold(n_splits = 5, random_state = 2021, shuffle = True)\n",
    "    # Iterate through each fold\n",
    "    for fold, (trn_ind, val_ind) in enumerate(kfold.split(train)):\n",
    "        print(f'Training fold {fold + 1}')\n",
    "        x_train, x_val = train.iloc[trn_ind], train.iloc[val_ind]\n",
    "        y_train, y_val = y.iloc[trn_ind], y.iloc[val_ind]\n",
    "        # Root mean squared percentage error weights\n",
    "        train_weights = 1 / np.square(y_train)\n",
    "        val_weights = 1 / np.square(y_val)\n",
    "        train_dataset = lgb.Dataset(x_train[features], y_train, weight = train_weights)\n",
    "        val_dataset = lgb.Dataset(x_val[features], y_val, weight = val_weights)\n",
    "        model = lgb.train(params = params,\n",
    "                          num_boost_round=1300,\n",
    "                          train_set = train_dataset, \n",
    "                          valid_sets = [train_dataset, val_dataset], \n",
    "                          verbose_eval = 250,\n",
    "                          early_stopping_rounds=50,\n",
    "                          feval = feval_rmspe)\n",
    "        # Add predictions to the out of folds array\n",
    "        oof_predictions[val_ind] = model.predict(x_val[features])\n",
    "        # Predict the test set\n",
    "        test_predictions += model.predict(test[features]) / 5\n",
    "    rmspe_score = rmspe(y, oof_predictions)\n",
    "    print(f'Our out of folds RMSPE is {rmspe_score}')\n",
    "    lgb.plot_importance(model,max_num_features=20)\n",
    "    # Return test predictions\n",
    "    return test_predictions\n",
    "# Traing and evaluate\n",
    "predictions_lgb_1= train_and_evaluate_lgb(train, test,params0)\n",
    "# predictions_lgb_2= train_and_evaluate_lgb(train, test,params1)\n",
    "# test['target'] = predictions_lgb_1\n",
    "# test[['row_id', 'target']].to_csv('submission.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abcfeb0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T17:24:56.433745Z",
     "iopub.status.busy": "2023-12-13T17:24:56.432837Z",
     "iopub.status.idle": "2023-12-13T17:24:56.436614Z",
     "shell.execute_reply": "2023-12-13T17:24:56.436066Z",
     "shell.execute_reply.started": "2023-12-13T11:55:17.974448Z"
    },
    "papermill": {
     "duration": 13.619172,
     "end_time": "2023-12-13T17:24:56.436773",
     "exception": false,
     "start_time": "2023-12-13T17:24:42.817601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da72feb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T17:25:23.508882Z",
     "iopub.status.busy": "2023-12-13T17:25:23.508247Z",
     "iopub.status.idle": "2023-12-13T17:25:29.007353Z",
     "shell.execute_reply": "2023-12-13T17:25:29.006623Z",
     "shell.execute_reply.started": "2023-12-13T12:20:52.897048Z"
    },
    "papermill": {
     "duration": 19.063371,
     "end_time": "2023-12-13T17:25:29.007503",
     "exception": false,
     "start_time": "2023-12-13T17:25:09.944132",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from numpy.random import seed\n",
    "seed(42)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "def root_mean_squared_per_error(y_true, y_pred):\n",
    "         return K.sqrt(K.mean(K.square( (y_true - y_pred)/ y_true )))\n",
    "    \n",
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=20, verbose=0,\n",
    "    mode='min',restore_best_weights=True)\n",
    "\n",
    "plateau = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.195, patience=7, verbose=0,\n",
    "    mode='min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e076a16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T17:25:56.205750Z",
     "iopub.status.busy": "2023-12-13T17:25:56.202036Z",
     "iopub.status.idle": "2023-12-13T17:26:05.148791Z",
     "shell.execute_reply": "2023-12-13T17:26:05.148006Z",
     "shell.execute_reply.started": "2023-12-13T12:21:01.051054Z"
    },
    "papermill": {
     "duration": 22.643394,
     "end_time": "2023-12-13T17:26:05.148960",
     "exception": false,
     "start_time": "2023-12-13T17:25:42.505566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# kfold based on the knn++ algorithm\n",
    "\n",
    "out_train = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\n",
    "out_train = out_train.pivot(index='time_id', columns='stock_id', values='target')\n",
    "\n",
    "#out_train[out_train.isna().any(axis=1)]\n",
    "out_train = out_train.fillna(out_train.mean())\n",
    "out_train.head()\n",
    "\n",
    "# code to add the just the read data after first execution\n",
    "\n",
    "# data separation based on knn ++\n",
    "nfolds = 5 # number of folds\n",
    "index = []\n",
    "totDist = []\n",
    "values = []\n",
    "# generates a matriz with the values of \n",
    "mat = out_train.values\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "mat = scaler.fit_transform(mat)\n",
    "\n",
    "nind = int(mat.shape[0]/nfolds) # number of individuals\n",
    "\n",
    "# adds index in the last column\n",
    "mat = np.c_[mat,np.arange(mat.shape[0])]\n",
    "\n",
    "\n",
    "lineNumber = np.random.choice(np.array(mat.shape[0]), size=nfolds, replace=False)\n",
    "\n",
    "lineNumber = np.sort(lineNumber)[::-1]\n",
    "\n",
    "for n in range(nfolds):\n",
    "    totDist.append(np.zeros(mat.shape[0]-nfolds))\n",
    "\n",
    "# saves index\n",
    "for n in range(nfolds):\n",
    "    \n",
    "    values.append([lineNumber[n]])    \n",
    "\n",
    "\n",
    "s=[]\n",
    "for n in range(nfolds):\n",
    "    s.append(mat[lineNumber[n],:])\n",
    "    \n",
    "    mat = np.delete(mat, obj=lineNumber[n], axis=0)\n",
    "\n",
    "for n in range(nind-1):    \n",
    "\n",
    "    luck = np.random.uniform(0,1,nfolds)\n",
    "    \n",
    "    for cycle in range(nfolds):\n",
    "         # saves the values of index           \n",
    "\n",
    "        s[cycle] = np.matlib.repmat(s[cycle], mat.shape[0], 1)\n",
    "\n",
    "        sumDist = np.sum( (mat[:,:-1] - s[cycle][:,:-1])**2 , axis=1)   \n",
    "        totDist[cycle] += sumDist        \n",
    "                \n",
    "        # probabilities\n",
    "        f = totDist[cycle]/np.sum(totDist[cycle]) # normalizing the totdist\n",
    "        j = 0\n",
    "        kn = 0\n",
    "        for val in f:\n",
    "            j += val        \n",
    "            if (j > luck[cycle]): # the column was selected\n",
    "                break\n",
    "            kn +=1\n",
    "        lineNumber[cycle] = kn\n",
    "        \n",
    "        # delete line of the value added    \n",
    "        for n_iter in range(nfolds):\n",
    "            \n",
    "            totDist[n_iter] = np.delete(totDist[n_iter],obj=lineNumber[cycle], axis=0)\n",
    "            j= 0\n",
    "        \n",
    "        s[cycle] = mat[lineNumber[cycle],:]\n",
    "        values[cycle].append(int(mat[lineNumber[cycle],-1]))\n",
    "        mat = np.delete(mat, obj=lineNumber[cycle], axis=0)\n",
    "\n",
    "\n",
    "for n_mod in range(nfolds):\n",
    "    values[n_mod] = out_train.index[values[n_mod]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aed72f01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T17:26:32.239960Z",
     "iopub.status.busy": "2023-12-13T17:26:32.239299Z",
     "iopub.status.idle": "2023-12-13T17:27:00.939995Z",
     "shell.execute_reply": "2023-12-13T17:27:00.939348Z",
     "shell.execute_reply.started": "2023-12-13T12:46:27.943480Z"
    },
    "papermill": {
     "duration": 42.274169,
     "end_time": "2023-12-13T17:27:00.940144",
     "exception": false,
     "start_time": "2023-12-13T17:26:18.665975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#colNames.remove('row_id')\n",
    "train.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "test.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "qt_train = []\n",
    "train_nn=train[colNames].copy()\n",
    "test_nn=test[colNames].copy()\n",
    "for col in colNames:\n",
    "    #print(col)\n",
    "    qt = QuantileTransformer(random_state=21,n_quantiles=2000, output_distribution='normal')\n",
    "    train_nn[col] = qt.fit_transform(train_nn[[col]])\n",
    "    test_nn[col] = qt.transform(test_nn[[col]])    \n",
    "    qt_train.append(qt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0aad9530",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T17:27:27.921110Z",
     "iopub.status.busy": "2023-12-13T17:27:27.920457Z",
     "iopub.status.idle": "2023-12-13T17:27:27.928958Z",
     "shell.execute_reply": "2023-12-13T17:27:27.928325Z",
     "shell.execute_reply.started": "2023-12-13T12:53:28.506385Z"
    },
    "papermill": {
     "duration": 13.55237,
     "end_time": "2023-12-13T17:27:27.929091",
     "exception": false,
     "start_time": "2023-12-13T17:27:14.376721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_nn[['stock_id','time_id','target']]=train[['stock_id','time_id','target']]\n",
    "test_nn[['stock_id','time_id']]=test[['stock_id','time_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "233fa69a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T17:27:55.031198Z",
     "iopub.status.busy": "2023-12-13T17:27:55.030566Z",
     "iopub.status.idle": "2023-12-13T17:27:56.999559Z",
     "shell.execute_reply": "2023-12-13T17:27:56.999084Z",
     "shell.execute_reply.started": "2023-12-13T12:53:30.879190Z"
    },
    "papermill": {
     "duration": 15.561077,
     "end_time": "2023-12-13T17:27:56.999694",
     "exception": false,
     "start_time": "2023-12-13T17:27:41.438617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 4 2 1 1 2 4 6 2 1 0 4 4 1 1 1 2 4 4 4 0 1 1 3 1 1 4 3 4 3 4 4 1 3 3 4\n",
      " 3 4 1 4 1 4 4 1 0 4 4 1 0 0 3 3 3 2 0 2 4 1 4 4 1 4 1 0 3 3 0 3 0 6 5 3 3\n",
      " 0 1 2 0 3 3 3 4 1 1 0 2 3 3 1 0 1 4 4 4 4 4 1 3 1 0 1 4 1 0 1 4 1 0 4 0 4\n",
      " 0]\n",
      "[1, 11, 22, 50, 55, 56, 62, 73, 76, 78, 84, 87, 96, 101, 112, 116, 122, 124, 126]\n",
      "[0, 4, 5, 10, 15, 16, 17, 23, 26, 28, 29, 36, 42, 44, 48, 53, 66, 69, 72, 85, 94, 95, 100, 102, 109, 111, 113, 115, 118, 120]\n",
      "[3, 6, 9, 18, 61, 63, 86, 97]\n",
      "[27, 31, 33, 37, 38, 40, 58, 59, 60, 74, 75, 77, 82, 83, 88, 89, 90, 98, 99, 110]\n",
      "[2, 7, 13, 14, 19, 20, 21, 30, 32, 34, 35, 39, 41, 43, 46, 47, 51, 52, 64, 67, 68, 70, 93, 103, 104, 105, 107, 108, 114, 119, 123, 125]\n",
      "[81]\n",
      "[8, 80]\n"
     ]
    }
   ],
   "source": [
    "# making agg features\n",
    "from sklearn.cluster import KMeans\n",
    "train_p = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\n",
    "train_p = train_p.pivot(index='time_id', columns='stock_id', values='target')\n",
    "\n",
    "corr = train_p.corr()\n",
    "\n",
    "ids = corr.index\n",
    "\n",
    "kmeans = KMeans(n_clusters=7, random_state=0).fit(corr.values)\n",
    "print(kmeans.labels_)\n",
    "\n",
    "l = []\n",
    "for n in range(7):\n",
    "    l.append ( [ (x-1) for x in ( (ids+1)*(kmeans.labels_ == n)) if x > 0] )\n",
    "    \n",
    "\n",
    "mat = []\n",
    "matTest = []\n",
    "\n",
    "n = 0\n",
    "for ind in l:\n",
    "    print(ind)\n",
    "    newDf = train_nn.loc[train_nn['stock_id'].isin(ind) ]\n",
    "    newDf = newDf.groupby(['time_id']).agg(np.nanmean)\n",
    "    newDf.loc[:,'stock_id'] = str(n)+'c1'\n",
    "    mat.append ( newDf )\n",
    "    \n",
    "    newDf = test_nn.loc[test_nn['stock_id'].isin(ind) ]    \n",
    "    newDf = newDf.groupby(['time_id']).agg(np.nanmean)\n",
    "    newDf.loc[:,'stock_id'] = str(n)+'c1'\n",
    "    matTest.append ( newDf )\n",
    "    \n",
    "    n+=1\n",
    "    \n",
    "mat1 = pd.concat(mat).reset_index()\n",
    "mat1.drop(columns=['target'],inplace=True)\n",
    "\n",
    "mat2 = pd.concat(matTest).reset_index()\n",
    "mat2 = pd.concat([mat2,mat1.loc[mat1.time_id==5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d73fab4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T17:28:23.777135Z",
     "iopub.status.busy": "2023-12-13T17:28:23.776143Z",
     "iopub.status.idle": "2023-12-13T17:28:23.779096Z",
     "shell.execute_reply": "2023-12-13T17:28:23.778548Z",
     "shell.execute_reply.started": "2023-12-13T12:53:37.524642Z"
    },
    "papermill": {
     "duration": 13.404579,
     "end_time": "2023-12-13T17:28:23.779239",
     "exception": false,
     "start_time": "2023-12-13T17:28:10.374660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nnn = ['time_id',\n",
    "     'log_return1_realized_volatility_0c1',\n",
    "     'log_return1_realized_volatility_1c1',     \n",
    "     'log_return1_realized_volatility_3c1',\n",
    "     'log_return1_realized_volatility_4c1',     \n",
    "     'log_return1_realized_volatility_6c1',\n",
    "     'total_volume_sum_0c1',\n",
    "     'total_volume_sum_1c1', \n",
    "     'total_volume_sum_3c1',\n",
    "     'total_volume_sum_4c1', \n",
    "     'total_volume_sum_6c1',\n",
    "     'trade_size_sum_0c1',\n",
    "     'trade_size_sum_1c1', \n",
    "     'trade_size_sum_3c1',\n",
    "     'trade_size_sum_4c1', \n",
    "     'trade_size_sum_6c1',\n",
    "     'trade_order_count_sum_0c1',\n",
    "     'trade_order_count_sum_1c1',\n",
    "     'trade_order_count_sum_3c1',\n",
    "     'trade_order_count_sum_4c1',\n",
    "     'trade_order_count_sum_6c1',      \n",
    "     'price_spread_sum_0c1',\n",
    "     'price_spread_sum_1c1',\n",
    "     'price_spread_sum_3c1',\n",
    "     'price_spread_sum_4c1',\n",
    "     'price_spread_sum_6c1',   \n",
    "     'bid_spread_sum_0c1',\n",
    "     'bid_spread_sum_1c1',\n",
    "     'bid_spread_sum_3c1',\n",
    "     'bid_spread_sum_4c1',\n",
    "     'bid_spread_sum_6c1',       \n",
    "     'ask_spread_sum_0c1',\n",
    "     'ask_spread_sum_1c1',\n",
    "     'ask_spread_sum_3c1',\n",
    "     'ask_spread_sum_4c1',\n",
    "     'ask_spread_sum_6c1',   \n",
    "     'volume_imbalance_sum_0c1',\n",
    "     'volume_imbalance_sum_1c1',\n",
    "     'volume_imbalance_sum_3c1',\n",
    "     'volume_imbalance_sum_4c1',\n",
    "     'volume_imbalance_sum_6c1',       \n",
    "     'bid_ask_spread_sum_0c1',\n",
    "     'bid_ask_spread_sum_1c1',\n",
    "     'bid_ask_spread_sum_3c1',\n",
    "     'bid_ask_spread_sum_4c1',\n",
    "     'bid_ask_spread_sum_6c1',\n",
    "     'size_tau2_0c1',\n",
    "     'size_tau2_1c1',\n",
    "     'size_tau2_3c1',\n",
    "     'size_tau2_4c1',\n",
    "     'size_tau2_6c1'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61b7c1e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T17:28:50.958997Z",
     "iopub.status.busy": "2023-12-13T17:28:50.958385Z",
     "iopub.status.idle": "2023-12-13T17:28:51.174630Z",
     "shell.execute_reply": "2023-12-13T17:28:51.175109Z",
     "shell.execute_reply.started": "2023-12-13T12:53:43.867189Z"
    },
    "papermill": {
     "duration": 13.831909,
     "end_time": "2023-12-13T17:28:51.175284",
     "exception": false,
     "start_time": "2023-12-13T17:28:37.343375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: Index.ravel returning ndarray is deprecated; in a future version this will return a view on self.\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: FutureWarning: Index.ravel returning ndarray is deprecated; in a future version this will return a view on self.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "mat1 = mat1.pivot(index='time_id', columns='stock_id')\n",
    "mat1.columns = [\"_\".join(x) for x in mat1.columns.ravel()]\n",
    "mat1.reset_index(inplace=True)\n",
    "\n",
    "mat2 = mat2.pivot(index='time_id', columns='stock_id')\n",
    "mat2.columns = [\"_\".join(x) for x in mat2.columns.ravel()]\n",
    "mat2.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d38334d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T17:29:18.332583Z",
     "iopub.status.busy": "2023-12-13T17:29:18.331683Z",
     "iopub.status.idle": "2023-12-13T17:29:32.268547Z",
     "shell.execute_reply": "2023-12-13T17:29:32.267947Z",
     "shell.execute_reply.started": "2023-12-13T12:53:47.350756Z"
    },
    "papermill": {
     "duration": 27.512828,
     "end_time": "2023-12-13T17:29:32.268677",
     "exception": false,
     "start_time": "2023-12-13T17:29:04.755849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "train_nn = pd.merge(train_nn,mat1[nnn],how='left',on='time_id')\n",
    "test_nn = pd.merge(test_nn,mat2[nnn],how='left',on='time_id')\n",
    "del mat1,mat2\n",
    "del train,test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc560f5",
   "metadata": {
    "papermill": {
     "duration": 13.47152,
     "end_time": "2023-12-13T17:29:59.233908",
     "exception": false,
     "start_time": "2023-12-13T17:29:45.762388",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## FFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf5b61e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T17:30:25.997596Z",
     "iopub.status.busy": "2023-12-13T17:30:25.996950Z",
     "iopub.status.idle": "2023-12-13T17:30:26.013290Z",
     "shell.execute_reply": "2023-12-13T17:30:26.012655Z",
     "shell.execute_reply.started": "2023-12-13T12:57:23.124477Z"
    },
    "papermill": {
     "duration": 13.413231,
     "end_time": "2023-12-13T17:30:26.013423",
     "exception": false,
     "start_time": "2023-12-13T17:30:12.600192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#https://bignerdranch.com/blog/implementing-swish-activation-function-in-keras/\n",
    "from keras.backend import sigmoid\n",
    "def swish(x, beta = 1):\n",
    "    return (x * sigmoid(beta * x))\n",
    "\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.layers import Activation\n",
    "get_custom_objects().update({'swish': Activation(swish)})\n",
    "\n",
    "hidden_units = (128,64,32)\n",
    "stock_embedding_size = 24\n",
    "\n",
    "cat_data = train_nn['stock_id']\n",
    "\n",
    "def base_model():\n",
    "    \n",
    "    # Each instance will consist of two inputs: a single user id, and a single movie id\n",
    "    stock_id_input = keras.Input(shape=(1,), name='stock_id')\n",
    "    num_input = keras.Input(shape=(276,), name='num_data')\n",
    "\n",
    "\n",
    "    #embedding, flatenning and concatenating\n",
    "    stock_embedded = keras.layers.Embedding(max(cat_data)+1, stock_embedding_size, \n",
    "                                           input_length=1, name='stock_embedding')(stock_id_input)\n",
    "    stock_flattened = keras.layers.Flatten()(stock_embedded)\n",
    "    out = keras.layers.Concatenate()([stock_flattened, num_input])\n",
    "    \n",
    "    # Add one or more hidden layers\n",
    "    for n_hidden in hidden_units:\n",
    "\n",
    "        out = keras.layers.Dense(n_hidden, activation='swish')(out)\n",
    "        \n",
    "\n",
    "    #out = keras.layers.Concatenate()([out, num_input])\n",
    "\n",
    "    # A single output: our predicted rating\n",
    "    out = keras.layers.Dense(1, activation='linear', name='prediction')(out)\n",
    "    \n",
    "    model = keras.Model(\n",
    "    inputs = [stock_id_input, num_input],\n",
    "    outputs = out,\n",
    "    )\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b6aa7bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T17:30:53.031720Z",
     "iopub.status.busy": "2023-12-13T17:30:53.030986Z",
     "iopub.status.idle": "2023-12-13T17:30:53.033946Z",
     "shell.execute_reply": "2023-12-13T17:30:53.033313Z",
     "shell.execute_reply.started": "2023-12-13T12:57:28.205844Z"
    },
    "papermill": {
     "duration": 13.411503,
     "end_time": "2023-12-13T17:30:53.034076",
     "exception": false,
     "start_time": "2023-12-13T17:30:39.622573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to calculate the root mean squared percentage error\n",
    "def rmspe(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "\n",
    "# Function to early stop with root mean squared percentage error\n",
    "def feval_rmspe(y_pred, lgb_train):\n",
    "    y_true = lgb_train.get_label()\n",
    "    return 'RMSPE', rmspe(y_true, y_pred), False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97026712",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T17:31:19.867982Z",
     "iopub.status.busy": "2023-12-13T17:31:19.852954Z",
     "iopub.status.idle": "2023-12-13T17:36:23.653782Z",
     "shell.execute_reply": "2023-12-13T17:36:23.653210Z",
     "shell.execute_reply.started": "2023-12-13T13:07:44.220554Z"
    },
    "papermill": {
     "duration": 317.172664,
     "end_time": "2023-12-13T17:36:23.653933",
     "exception": false,
     "start_time": "2023-12-13T17:31:06.481269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV 1/5\n",
      "Epoch 1/1000\n",
      "168/168 [==============================] - 3s 10ms/step - loss: 22.6877 - val_loss: 1.7882\n",
      "Epoch 2/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.9153 - val_loss: 0.6510\n",
      "Epoch 3/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.6791 - val_loss: 0.4982\n",
      "Epoch 4/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.6063 - val_loss: 0.5735\n",
      "Epoch 5/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.4864 - val_loss: 0.3252\n",
      "Epoch 6/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.3658 - val_loss: 2.8641\n",
      "Epoch 7/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.9092 - val_loss: 0.2422\n",
      "Epoch 8/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2809 - val_loss: 0.3179\n",
      "Epoch 9/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.3134 - val_loss: 0.4352\n",
      "Epoch 10/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.5070 - val_loss: 2.5512\n",
      "Epoch 11/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.6662 - val_loss: 0.4738\n",
      "Epoch 12/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.3886 - val_loss: 0.4041\n",
      "Epoch 13/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.3124 - val_loss: 0.2184\n",
      "Epoch 14/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2329 - val_loss: 0.2203\n",
      "Epoch 15/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2341 - val_loss: 0.2398\n",
      "Epoch 16/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2788 - val_loss: 0.2381\n",
      "Epoch 17/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2411 - val_loss: 0.2542\n",
      "Epoch 18/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2569 - val_loss: 0.2290\n",
      "Epoch 19/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2544 - val_loss: 0.2158\n",
      "Epoch 20/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2465 - val_loss: 0.2131\n",
      "Epoch 21/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2489 - val_loss: 0.2221\n",
      "Epoch 22/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2532 - val_loss: 0.2209\n",
      "Epoch 23/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2539 - val_loss: 0.2858\n",
      "Epoch 24/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2383 - val_loss: 0.2133\n",
      "Epoch 25/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2405 - val_loss: 0.2532\n",
      "Epoch 26/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2403 - val_loss: 0.2859\n",
      "Epoch 27/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2563 - val_loss: 0.2133\n",
      "Epoch 28/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2078 - val_loss: 0.2081\n",
      "Epoch 29/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2061 - val_loss: 0.2086\n",
      "Epoch 30/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2050 - val_loss: 0.2086\n",
      "Epoch 31/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2060 - val_loss: 0.2093\n",
      "Epoch 32/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2057 - val_loss: 0.2089\n",
      "Epoch 33/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2055 - val_loss: 0.2085\n",
      "Epoch 34/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2048 - val_loss: 0.2235\n",
      "Epoch 35/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2114 - val_loss: 0.2101\n",
      "Epoch 36/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2044 - val_loss: 0.2088\n",
      "Epoch 37/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2033 - val_loss: 0.2080\n",
      "Epoch 38/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2033 - val_loss: 0.2080\n",
      "Epoch 39/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2031 - val_loss: 0.2090\n",
      "Epoch 40/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2029 - val_loss: 0.2089\n",
      "Epoch 41/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2033 - val_loss: 0.2087\n",
      "Epoch 42/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2031 - val_loss: 0.2080\n",
      "Epoch 43/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2036 - val_loss: 0.2089\n",
      "Epoch 44/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2036 - val_loss: 0.2092\n",
      "Epoch 45/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2031 - val_loss: 0.2081\n",
      "Epoch 46/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2032 - val_loss: 0.2080\n",
      "Epoch 47/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2026 - val_loss: 0.2083\n",
      "Epoch 48/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2016 - val_loss: 0.2080\n",
      "Epoch 49/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2022 - val_loss: 0.2079\n",
      "Epoch 50/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2023 - val_loss: 0.2080\n",
      "Epoch 51/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2031 - val_loss: 0.2082\n",
      "Epoch 52/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2027 - val_loss: 0.2083\n",
      "Epoch 53/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2022 - val_loss: 0.2081\n",
      "Epoch 54/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2025 - val_loss: 0.2081\n",
      "Epoch 55/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2023 - val_loss: 0.2083\n",
      "Epoch 56/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2020 - val_loss: 0.2080\n",
      "Epoch 57/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2015 - val_loss: 0.2080\n",
      "Epoch 58/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2020 - val_loss: 0.2082\n",
      "Epoch 59/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2010 - val_loss: 0.2080\n",
      "Epoch 60/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2022 - val_loss: 0.2081\n",
      "Epoch 61/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2016 - val_loss: 0.2080\n",
      "Epoch 62/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2019 - val_loss: 0.2080\n",
      "Epoch 63/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2019 - val_loss: 0.2080\n",
      "Epoch 64/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2015 - val_loss: 0.2081\n",
      "Epoch 65/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2021 - val_loss: 0.2081\n",
      "Epoch 66/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2020 - val_loss: 0.2081\n",
      "Epoch 67/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2013 - val_loss: 0.2081\n",
      "Epoch 68/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2027 - val_loss: 0.2081\n",
      "Epoch 69/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2011 - val_loss: 0.2081\n",
      "Fold 1 NN: 0.20795\n",
      "CV 2/5\n",
      "Epoch 1/1000\n",
      "168/168 [==============================] - 2s 7ms/step - loss: 26.5246 - val_loss: 0.5266\n",
      "Epoch 2/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.9618 - val_loss: 0.9174\n",
      "Epoch 3/1000\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7685 - val_loss: 2.2881\n",
      "Epoch 4/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.6339 - val_loss: 0.3307\n",
      "Epoch 5/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.2617 - val_loss: 0.3011\n",
      "Epoch 6/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.3358 - val_loss: 0.3348\n",
      "Epoch 7/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.4169 - val_loss: 0.6875\n",
      "Epoch 8/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.6735 - val_loss: 0.2649\n",
      "Epoch 9/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2989 - val_loss: 0.4089\n",
      "Epoch 10/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.3107 - val_loss: 0.3531\n",
      "Epoch 11/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.0043 - val_loss: 0.6558\n",
      "Epoch 12/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.3563 - val_loss: 0.2442\n",
      "Epoch 13/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2554 - val_loss: 0.2563\n",
      "Epoch 14/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2548 - val_loss: 0.2578\n",
      "Epoch 15/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2577 - val_loss: 0.2468\n",
      "Epoch 16/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2588 - val_loss: 0.2923\n",
      "Epoch 17/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2821 - val_loss: 0.2831\n",
      "Epoch 18/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2713 - val_loss: 0.2685\n",
      "Epoch 19/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2797 - val_loss: 0.2639\n",
      "Epoch 20/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.2182 - val_loss: 0.2199\n",
      "Epoch 21/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2091 - val_loss: 0.2198\n",
      "Epoch 22/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2080 - val_loss: 0.2229\n",
      "Epoch 23/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2101 - val_loss: 0.2167\n",
      "Epoch 24/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2088 - val_loss: 0.2163\n",
      "Epoch 25/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2086 - val_loss: 0.2173\n",
      "Epoch 26/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2086 - val_loss: 0.2186\n",
      "Epoch 27/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2079 - val_loss: 0.2225\n",
      "Epoch 28/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2099 - val_loss: 0.2182\n",
      "Epoch 29/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2119 - val_loss: 0.2151\n",
      "Epoch 30/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2081 - val_loss: 0.2155\n",
      "Epoch 31/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2090 - val_loss: 0.2218\n",
      "Epoch 32/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2087 - val_loss: 0.2177\n",
      "Epoch 33/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2097 - val_loss: 0.2164\n",
      "Epoch 34/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2091 - val_loss: 0.2181\n",
      "Epoch 35/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2082 - val_loss: 0.2189\n",
      "Epoch 36/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2106 - val_loss: 0.2213\n",
      "Epoch 37/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2049 - val_loss: 0.2150\n",
      "Epoch 38/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2036 - val_loss: 0.2150\n",
      "Epoch 39/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2035 - val_loss: 0.2137\n",
      "Epoch 40/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2031 - val_loss: 0.2149\n",
      "Epoch 41/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2032 - val_loss: 0.2148\n",
      "Epoch 42/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2030 - val_loss: 0.2145\n",
      "Epoch 43/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2039 - val_loss: 0.2152\n",
      "Epoch 44/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2032 - val_loss: 0.2141\n",
      "Epoch 45/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2031 - val_loss: 0.2138\n",
      "Epoch 46/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2035 - val_loss: 0.2167\n",
      "Epoch 47/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.2016 - val_loss: 0.2134\n",
      "Epoch 48/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2019 - val_loss: 0.2138\n",
      "Epoch 49/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.2018 - val_loss: 0.2140\n",
      "Epoch 50/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.2012 - val_loss: 0.2137\n",
      "Epoch 51/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.2016 - val_loss: 0.2140\n",
      "Epoch 52/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.2018 - val_loss: 0.2131\n",
      "Epoch 53/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2012 - val_loss: 0.2131\n",
      "Epoch 54/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2023 - val_loss: 0.2137\n",
      "Epoch 55/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2016 - val_loss: 0.2144\n",
      "Epoch 56/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2012 - val_loss: 0.2139\n",
      "Epoch 57/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2018 - val_loss: 0.2144\n",
      "Epoch 58/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.2014 - val_loss: 0.2145\n",
      "Epoch 59/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2014 - val_loss: 0.2139\n",
      "Epoch 60/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2011 - val_loss: 0.2137\n",
      "Epoch 61/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2009 - val_loss: 0.2140\n",
      "Epoch 62/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2004 - val_loss: 0.2139\n",
      "Epoch 63/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2013 - val_loss: 0.2141\n",
      "Epoch 64/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2005 - val_loss: 0.2142\n",
      "Epoch 65/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2011 - val_loss: 0.2140\n",
      "Epoch 66/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2015 - val_loss: 0.2142\n",
      "Epoch 67/1000\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.2008 - val_loss: 0.2134\n",
      "Epoch 68/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2012 - val_loss: 0.2139\n",
      "Epoch 69/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2009 - val_loss: 0.2136\n",
      "Epoch 70/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2008 - val_loss: 0.2136\n",
      "Epoch 71/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2006 - val_loss: 0.2136\n",
      "Epoch 72/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2005 - val_loss: 0.2136\n",
      "Fold 2 NN: 0.21307\n",
      "CV 3/5\n",
      "Epoch 1/1000\n",
      "168/168 [==============================] - 2s 8ms/step - loss: 26.6912 - val_loss: 0.6662\n",
      "Epoch 2/1000\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.7493 - val_loss: 0.6094\n",
      "Epoch 3/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.6244 - val_loss: 0.5878\n",
      "Epoch 4/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.6243 - val_loss: 0.5725\n",
      "Epoch 5/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.5818 - val_loss: 0.4651\n",
      "Epoch 6/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.5408 - val_loss: 0.4145\n",
      "Epoch 7/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.8039 - val_loss: 0.4438\n",
      "Epoch 8/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.4414 - val_loss: 0.3611\n",
      "Epoch 9/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.4422 - val_loss: 0.4519\n",
      "Epoch 10/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.4401 - val_loss: 0.2951\n",
      "Epoch 11/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.4164 - val_loss: 0.3459\n",
      "Epoch 12/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.4029 - val_loss: 0.3308\n",
      "Epoch 13/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.7264 - val_loss: 0.2591\n",
      "Epoch 14/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2270 - val_loss: 0.2278\n",
      "Epoch 15/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2325 - val_loss: 0.2222\n",
      "Epoch 16/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2251 - val_loss: 0.2401\n",
      "Epoch 17/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2295 - val_loss: 0.2485\n",
      "Epoch 18/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2382 - val_loss: 0.2193\n",
      "Epoch 19/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2469 - val_loss: 0.3054\n",
      "Epoch 20/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.2484 - val_loss: 0.2658\n",
      "Epoch 21/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2511 - val_loss: 0.2420\n",
      "Epoch 22/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.3061 - val_loss: 0.2568\n",
      "Epoch 23/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2558 - val_loss: 0.2846\n",
      "Epoch 24/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2523 - val_loss: 0.2363\n",
      "Epoch 25/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2359 - val_loss: 0.2481\n",
      "Epoch 26/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.2121 - val_loss: 0.2094\n",
      "Epoch 27/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.2073 - val_loss: 0.2102\n",
      "Epoch 28/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2072 - val_loss: 0.2115\n",
      "Epoch 29/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.2066 - val_loss: 0.2158\n",
      "Epoch 30/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2085 - val_loss: 0.2104\n",
      "Epoch 31/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.2056 - val_loss: 0.2118\n",
      "Epoch 32/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2075 - val_loss: 0.2114\n",
      "Epoch 33/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2090 - val_loss: 0.2103\n",
      "Epoch 34/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2047 - val_loss: 0.2104\n",
      "Epoch 35/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.2044 - val_loss: 0.2100\n",
      "Epoch 36/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.2037 - val_loss: 0.2104\n",
      "Epoch 37/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2032 - val_loss: 0.2106\n",
      "Epoch 38/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.2034 - val_loss: 0.2106\n",
      "Epoch 39/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.2029 - val_loss: 0.2104\n",
      "Epoch 40/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2037 - val_loss: 0.2103\n",
      "Epoch 41/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2030 - val_loss: 0.2102\n",
      "Epoch 42/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2042 - val_loss: 0.2101\n",
      "Epoch 43/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2033 - val_loss: 0.2102\n",
      "Epoch 44/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2025 - val_loss: 0.2100\n",
      "Epoch 45/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2032 - val_loss: 0.2101\n",
      "Epoch 46/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2029 - val_loss: 0.2101\n",
      "Fold 3 NN: 0.20941\n",
      "CV 4/5\n",
      "Epoch 1/1000\n",
      "168/168 [==============================] - 2s 6ms/step - loss: 36.1684 - val_loss: 1.4004\n",
      "Epoch 2/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.9063 - val_loss: 0.7478\n",
      "Epoch 3/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.7243 - val_loss: 0.7406\n",
      "Epoch 4/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.6432 - val_loss: 0.6156\n",
      "Epoch 5/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.6433 - val_loss: 0.4956\n",
      "Epoch 6/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.5698 - val_loss: 0.6028\n",
      "Epoch 7/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.5884 - val_loss: 0.4224\n",
      "Epoch 8/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.5032 - val_loss: 0.5738\n",
      "Epoch 9/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.5242 - val_loss: 0.4584\n",
      "Epoch 10/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.4566 - val_loss: 0.2808\n",
      "Epoch 11/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2430 - val_loss: 0.2325\n",
      "Epoch 12/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2445 - val_loss: 0.2753\n",
      "Epoch 13/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.2468 - val_loss: 0.2247\n",
      "Epoch 14/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2719 - val_loss: 9.2817\n",
      "Epoch 15/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 2.1479 - val_loss: 0.3086\n",
      "Epoch 16/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2413 - val_loss: 0.2656\n",
      "Epoch 17/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2306 - val_loss: 0.2281\n",
      "Epoch 18/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2237 - val_loss: 0.2228\n",
      "Epoch 19/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2303 - val_loss: 0.2341\n",
      "Epoch 20/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2331 - val_loss: 0.3565\n",
      "Epoch 21/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2501 - val_loss: 0.3024\n",
      "Epoch 22/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2476 - val_loss: 0.2768\n",
      "Epoch 23/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2463 - val_loss: 0.2231\n",
      "Epoch 24/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2364 - val_loss: 0.2589\n",
      "Epoch 25/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2438 - val_loss: 0.2553\n",
      "Epoch 26/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2128 - val_loss: 0.2168\n",
      "Epoch 27/1000\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.2065 - val_loss: 0.2189\n",
      "Epoch 28/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2063 - val_loss: 0.2175\n",
      "Epoch 29/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2055 - val_loss: 0.2164\n",
      "Epoch 30/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2064 - val_loss: 0.2161\n",
      "Epoch 31/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2062 - val_loss: 0.2166\n",
      "Epoch 32/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2055 - val_loss: 0.2174\n",
      "Epoch 33/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2054 - val_loss: 0.2170\n",
      "Epoch 34/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2056 - val_loss: 0.2165\n",
      "Epoch 35/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2049 - val_loss: 0.2202\n",
      "Epoch 36/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2065 - val_loss: 0.2190\n",
      "Epoch 37/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2082 - val_loss: 0.2164\n",
      "Epoch 38/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2033 - val_loss: 0.2159\n",
      "Epoch 39/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2031 - val_loss: 0.2157\n",
      "Epoch 40/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2032 - val_loss: 0.2153\n",
      "Epoch 41/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2030 - val_loss: 0.2158\n",
      "Epoch 42/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2025 - val_loss: 0.2164\n",
      "Epoch 43/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.2029 - val_loss: 0.2150\n",
      "Epoch 44/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2024 - val_loss: 0.2161\n",
      "Epoch 45/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2020 - val_loss: 0.2166\n",
      "Epoch 46/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2032 - val_loss: 0.2169\n",
      "Epoch 47/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2024 - val_loss: 0.2183\n",
      "Epoch 48/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2026 - val_loss: 0.2159\n",
      "Epoch 49/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2021 - val_loss: 0.2161\n",
      "Epoch 50/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2024 - val_loss: 0.2172\n",
      "Epoch 51/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2010 - val_loss: 0.2157\n",
      "Epoch 52/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2008 - val_loss: 0.2157\n",
      "Epoch 53/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2016 - val_loss: 0.2155\n",
      "Epoch 54/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2014 - val_loss: 0.2161\n",
      "Epoch 55/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2019 - val_loss: 0.2161\n",
      "Epoch 56/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2010 - val_loss: 0.2160\n",
      "Epoch 57/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2011 - val_loss: 0.2153\n",
      "Epoch 58/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2013 - val_loss: 0.2154\n",
      "Epoch 59/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2007 - val_loss: 0.2156\n",
      "Epoch 60/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2016 - val_loss: 0.2156\n",
      "Epoch 61/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2013 - val_loss: 0.2156\n",
      "Epoch 62/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2007 - val_loss: 0.2154\n",
      "Epoch 63/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2013 - val_loss: 0.2154\n",
      "Fold 4 NN: 0.21501\n",
      "CV 5/5\n",
      "Epoch 1/1000\n",
      "168/168 [==============================] - 2s 6ms/step - loss: 26.4445 - val_loss: 0.7371\n",
      "Epoch 2/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.7399 - val_loss: 0.4438\n",
      "Epoch 3/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.3954 - val_loss: 0.7947\n",
      "Epoch 4/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.6196 - val_loss: 0.4074\n",
      "Epoch 5/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.3506 - val_loss: 0.3957\n",
      "Epoch 6/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.3481 - val_loss: 5.3807\n",
      "Epoch 7/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 2.6073 - val_loss: 0.4789\n",
      "Epoch 8/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.4871 - val_loss: 0.4262\n",
      "Epoch 9/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.4419 - val_loss: 0.4208\n",
      "Epoch 10/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.4206 - val_loss: 0.4393\n",
      "Epoch 11/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.3982 - val_loss: 0.3166\n",
      "Epoch 12/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.3916 - val_loss: 0.9922\n",
      "Epoch 13/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.5261 - val_loss: 0.2413\n",
      "Epoch 14/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2320 - val_loss: 0.2215\n",
      "Epoch 15/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.2212 - val_loss: 0.3106\n",
      "Epoch 16/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.8353 - val_loss: 0.2386\n",
      "Epoch 17/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.2317 - val_loss: 0.2347\n",
      "Epoch 18/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.2468 - val_loss: 0.2360\n",
      "Epoch 19/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2280 - val_loss: 0.3511\n",
      "Epoch 20/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.3039 - val_loss: 0.2591\n",
      "Epoch 21/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.2317 - val_loss: 0.8238\n",
      "Epoch 22/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.3054 - val_loss: 0.2159\n",
      "Epoch 23/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.2090 - val_loss: 0.2152\n",
      "Epoch 24/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2075 - val_loss: 0.2174\n",
      "Epoch 25/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2091 - val_loss: 0.2154\n",
      "Epoch 26/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.2077 - val_loss: 0.2148\n",
      "Epoch 27/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2084 - val_loss: 0.2203\n",
      "Epoch 28/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2076 - val_loss: 0.2148\n",
      "Epoch 29/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.2068 - val_loss: 0.2143\n",
      "Epoch 30/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.2063 - val_loss: 0.2155\n",
      "Epoch 31/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2061 - val_loss: 0.2256\n",
      "Epoch 32/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.2095 - val_loss: 0.2149\n",
      "Epoch 33/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2075 - val_loss: 0.2149\n",
      "Epoch 34/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2071 - val_loss: 0.2163\n",
      "Epoch 35/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2080 - val_loss: 0.2143\n",
      "Epoch 36/1000\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.2068 - val_loss: 0.2189\n",
      "Epoch 37/1000\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.2041 - val_loss: 0.2152\n",
      "Epoch 38/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2034 - val_loss: 0.2141\n",
      "Epoch 39/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2026 - val_loss: 0.2142\n",
      "Epoch 40/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2028 - val_loss: 0.2136\n",
      "Epoch 41/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2027 - val_loss: 0.2134\n",
      "Epoch 42/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2028 - val_loss: 0.2134\n",
      "Epoch 43/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2025 - val_loss: 0.2143\n",
      "Epoch 44/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2029 - val_loss: 0.2135\n",
      "Epoch 45/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2027 - val_loss: 0.2133\n",
      "Epoch 46/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2032 - val_loss: 0.2138\n",
      "Epoch 47/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2032 - val_loss: 0.2135\n",
      "Epoch 48/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2034 - val_loss: 0.2192\n",
      "Epoch 49/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2032 - val_loss: 0.2133\n",
      "Epoch 50/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2020 - val_loss: 0.2130\n",
      "Epoch 51/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2019 - val_loss: 0.2130\n",
      "Epoch 52/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2015 - val_loss: 0.2136\n",
      "Epoch 53/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2019 - val_loss: 0.2129\n",
      "Epoch 54/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2016 - val_loss: 0.2129\n",
      "Epoch 55/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2027 - val_loss: 0.2140\n",
      "Epoch 56/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2015 - val_loss: 0.2131\n",
      "Epoch 57/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2014 - val_loss: 0.2132\n",
      "Epoch 58/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2024 - val_loss: 0.2138\n",
      "Epoch 59/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2008 - val_loss: 0.2130\n",
      "Epoch 60/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2014 - val_loss: 0.2145\n",
      "Epoch 61/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2012 - val_loss: 0.2127\n",
      "Epoch 62/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2017 - val_loss: 0.2127\n",
      "Epoch 63/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2008 - val_loss: 0.2127\n",
      "Epoch 64/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2010 - val_loss: 0.2128\n",
      "Epoch 65/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.2013 - val_loss: 0.2127\n",
      "Epoch 66/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2011 - val_loss: 0.2130\n",
      "Epoch 67/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2014 - val_loss: 0.2129\n",
      "Epoch 68/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.2016 - val_loss: 0.2129\n",
      "Epoch 69/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.2016 - val_loss: 0.2129\n",
      "Epoch 70/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2008 - val_loss: 0.2128\n",
      "Epoch 71/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.2012 - val_loss: 0.2129\n",
      "Epoch 72/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.2009 - val_loss: 0.2128\n",
      "Epoch 73/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2025 - val_loss: 0.2130\n",
      "Epoch 74/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2012 - val_loss: 0.2128\n",
      "Epoch 75/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2015 - val_loss: 0.2129\n",
      "Epoch 76/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2014 - val_loss: 0.2129\n",
      "Epoch 77/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2014 - val_loss: 0.2129\n",
      "Epoch 78/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2008 - val_loss: 0.2129\n",
      "Epoch 79/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2009 - val_loss: 0.2129\n",
      "Epoch 80/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.2014 - val_loss: 0.2128\n",
      "Epoch 81/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.2007 - val_loss: 0.2129\n",
      "Epoch 82/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2011 - val_loss: 0.2129\n",
      "Epoch 83/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2021 - val_loss: 0.2129\n",
      "Epoch 84/1000\n",
      "168/168 [==============================] - 1s 4ms/step - loss: 0.2015 - val_loss: 0.2129\n",
      "Epoch 85/1000\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2013 - val_loss: 0.2129\n",
      "Fold 5 NN: 0.21266\n"
     ]
    }
   ],
   "source": [
    "plateau = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.19, patience=7, verbose=0,\n",
    "    mode='min')\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=20, verbose=0,\n",
    "    mode='min',restore_best_weights=True)\n",
    "\n",
    "target_name='target'\n",
    "scores_folds = {}\n",
    "model_name = 'NN'\n",
    "pred_name = 'pred_{}'.format(model_name)\n",
    "\n",
    "n_folds = 5\n",
    "kf = model_selection.KFold(n_splits=n_folds, shuffle=True, random_state=2020)\n",
    "scores_folds[model_name] = []\n",
    "counter = 1\n",
    "\n",
    "features_to_consider = list(train_nn)\n",
    "\n",
    "features_to_consider.remove('time_id')\n",
    "features_to_consider.remove('target')\n",
    "try:\n",
    "    features_to_consider.remove('pred_NN')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "train_nn[features_to_consider] = train_nn[features_to_consider].fillna(train_nn[features_to_consider].mean())\n",
    "test_nn[features_to_consider] = test_nn[features_to_consider].fillna(train_nn[features_to_consider].mean())\n",
    "\n",
    "train_nn[pred_name] = 0\n",
    "test_nn[target_name] = 0\n",
    "test_predictions_nn = np.zeros(test_nn.shape[0])\n",
    "\n",
    "for n_count in range(n_folds):\n",
    "    print('CV {}/{}'.format(counter, n_folds))\n",
    "    \n",
    "    indexes = np.arange(nfolds).astype(int)    \n",
    "    indexes = np.delete(indexes,obj=n_count, axis=0) \n",
    "    \n",
    "    indexes = np.r_[values[indexes[0]],values[indexes[1]],values[indexes[2]],values[indexes[3]]]\n",
    "    \n",
    "    X_train = train_nn.loc[train_nn.time_id.isin(indexes), features_to_consider]\n",
    "    y_train = train_nn.loc[train_nn.time_id.isin(indexes), target_name]\n",
    "    X_test = train_nn.loc[train_nn.time_id.isin(values[n_count]), features_to_consider]\n",
    "    y_test = train_nn.loc[train_nn.time_id.isin(values[n_count]), target_name]\n",
    "    \n",
    "    #############################################################################################\n",
    "    # NN\n",
    "    #############################################################################################\n",
    "    \n",
    "    model = base_model()\n",
    "    \n",
    "    model.compile(\n",
    "        keras.optimizers.Adam(learning_rate=0.006),\n",
    "        loss=root_mean_squared_per_error\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        features_to_consider.remove('stock_id')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    num_data = X_train[features_to_consider]\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))         \n",
    "    num_data = scaler.fit_transform(num_data.values)    \n",
    "    \n",
    "    cat_data = X_train['stock_id']    \n",
    "    target =  y_train\n",
    "    \n",
    "    num_data_test = X_test[features_to_consider]\n",
    "    num_data_test = scaler.transform(num_data_test.values)\n",
    "    cat_data_test = X_test['stock_id']\n",
    "\n",
    "    model.fit([cat_data, num_data], \n",
    "              target,               \n",
    "              batch_size=2048,\n",
    "              epochs=1000,\n",
    "              validation_data=([cat_data_test, num_data_test], y_test),\n",
    "              callbacks=[es, plateau],\n",
    "              validation_batch_size=len(y_test),\n",
    "              shuffle=True,\n",
    "             verbose = 1)\n",
    "\n",
    "    preds = model.predict([cat_data_test, num_data_test]).reshape(1,-1)[0]\n",
    "    \n",
    "    score = round(rmspe(y_true = y_test, y_pred = preds),5)\n",
    "    print('Fold {} {}: {}'.format(counter, model_name, score))\n",
    "    scores_folds[model_name].append(score)\n",
    "    \n",
    "    tt =scaler.transform(test_nn[features_to_consider].values)\n",
    "    #test_nn[target_name] += model.predict([test_nn['stock_id'], tt]).reshape(1,-1)[0].clip(0,1e10)\n",
    "    test_predictions_nn += model.predict([test_nn['stock_id'], tt]).reshape(1,-1)[0].clip(0,1e10)/n_folds\n",
    "    #test[target_name] += model.predict([test['stock_id'], test[features_to_consider]]).reshape(1,-1)[0].clip(0,1e10)\n",
    "       \n",
    "    counter += 1\n",
    "    features_to_consider.append('stock_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c783cb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T17:36:53.791113Z",
     "iopub.status.busy": "2023-12-13T17:36:53.789786Z",
     "iopub.status.idle": "2023-12-13T17:36:53.813063Z",
     "shell.execute_reply": "2023-12-13T17:36:53.812379Z",
     "shell.execute_reply.started": "2023-12-13T13:07:25.448684Z"
    },
    "papermill": {
     "duration": 15.077172,
     "end_time": "2023-12-13T17:36:53.813212",
     "exception": false,
     "start_time": "2023-12-13T17:36:38.736040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSPE NN: 1.0 - Folds: [0.20795, 0.21307, 0.20941, 0.21501, 0.21266]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0-34</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  row_id  target\n",
       "0    0-4     NaN\n",
       "1   0-32     NaN\n",
       "2   0-34     NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_nn[\"row_id\"] = test_nn[\"stock_id\"].astype(str) + \"-\" + test_nn[\"time_id\"].astype(str) \n",
    "#test_nn[target_name] = (test_predictions_nn*0.455+predictions_lgb_1*0.265+preds_tab*0.3)\n",
    "test_nn[target_name] = (test_predictions_nn*0.4+predictions_lgb_1*0.3+tab_preds*0.3)\n",
    "\n",
    "\n",
    "score = round(rmspe(y_true = train_nn[target_name].values, y_pred = train_nn[pred_name].values),5)\n",
    "print('RMSPE {}: {} - Folds: {}'.format(model_name, score, scores_folds[model_name]))\n",
    "\n",
    "display(test_nn[['row_id', target_name]].head(3))\n",
    "test_nn[['row_id', target_name]].to_csv('submission.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41574932",
   "metadata": {
    "papermill": {
     "duration": 15.172958,
     "end_time": "2023-12-13T17:37:24.052344",
     "exception": false,
     "start_time": "2023-12-13T17:37:08.879386",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It's a fork from https://www.kaggle.com/alexioslyon/lgbm-baseline and other great kaggles.thanks a lot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa350cce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T17:37:54.196502Z",
     "iopub.status.busy": "2023-12-13T17:37:54.195854Z",
     "iopub.status.idle": "2023-12-13T17:37:54.198753Z",
     "shell.execute_reply": "2023-12-13T17:37:54.198164Z"
    },
    "papermill": {
     "duration": 15.065912,
     "end_time": "2023-12-13T17:37:54.198878",
     "exception": false,
     "start_time": "2023-12-13T17:37:39.132966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# total time is around 2:30"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 2344753,
     "sourceId": 27233,
     "sourceType": "competition"
    },
    {
     "datasetId": 921302,
     "sourceId": 6182088,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4119387,
     "sourceId": 7138177,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30120,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13415.674681,
   "end_time": "2023-12-13T17:38:12.454220",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-13T13:54:36.779539",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
